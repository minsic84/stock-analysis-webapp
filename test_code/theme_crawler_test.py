#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ë„¤ì´ë²„ ê¸ˆìœµ í…Œë§ˆ + ë‰´ìŠ¤ í¬ë¡¤ë§ + DB ì €ì¥
- í…Œë§ˆë³„ ìƒìœ„ 3ê°œ ì¢…ëª©ì˜ ë‰´ìŠ¤ 5ê°œì”© ìˆ˜ì§‘
- MySQL DBì— JSON í˜•íƒœë¡œ ì €ì¥
- DB ì €ì¥ ê²°ê³¼ë§Œ ì½˜ì†” ì¶œë ¥
"""

import requests
from bs4 import BeautifulSoup
import time
import re
import json
import pymysql
from datetime import datetime, timedelta
from urllib.parse import urljoin
from dotenv import load_dotenv
import os

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()


def clean_text(text):
    """í…ìŠ¤íŠ¸ ì •ë¦¬"""
    if not text:
        return ""
    return text.strip().replace('\n', '').replace('\t', '').replace('\xa0', '').replace(',', '')


def parse_number(text):
    """ìˆ«ì íŒŒì‹±"""
    if not text:
        return 0
    try:
        clean_num = re.sub(r'[^\d.-]', '', str(text))
        return int(float(clean_num)) if clean_num else 0
    except:
        return 0


def parse_percentage(text):
    """í¼ì„¼íŠ¸ íŒŒì‹±"""
    if not text:
        return 0
    try:
        match = re.search(r'([+-]?\d+\.?\d*)%?', str(text))
        if match:
            return float(match.group(1))
        return 0
    except:
        return 0


def get_db_connection():
    """DB ì—°ê²°"""
    try:
        connection = pymysql.connect(
            host=os.getenv('DB_HOST', 'localhost'),
            port=int(os.getenv('DB_PORT', 3306)),
            user=os.getenv('DB_USER'),
            password=os.getenv('DB_PASSWORD'),
            charset='utf8mb4',
            autocommit=True
        )
        return connection
    except Exception as e:
        print(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
        return None


def setup_database():
    """DB ìŠ¤í‚¤ë§ˆ ë° í…Œì´ë¸” ì„¤ì •"""
    print("ğŸ—„ï¸ DB ì„¤ì • ì‹œì‘...")

    connection = get_db_connection()
    if not connection:
        return False

    try:
        cursor = connection.cursor()

        # 1. crawling_db ìŠ¤í‚¤ë§ˆ ìƒì„±
        cursor.execute("CREATE DATABASE IF NOT EXISTS crawling_db CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci")
        print("   âœ… crawling_db ìŠ¤í‚¤ë§ˆ ìƒì„±/í™•ì¸ ì™„ë£Œ")

        # 2. crawling_db ì‚¬ìš©
        cursor.execute("USE crawling_db")

        # 3. ì˜¤ëŠ˜ ë‚ ì§œ í…Œì´ë¸”ëª…
        today = datetime.now().strftime('%Y%m%d')
        table_name = f"theme_{today}"

        # 4. ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ (ìˆë‹¤ë©´)
        cursor.execute(f"DROP TABLE IF EXISTS {table_name}")
        print(f"   ğŸ—‘ï¸ ê¸°ì¡´ {table_name} í…Œì´ë¸” ì‚­ì œ")

        # 5. ìƒˆ í…Œì´ë¸” ìƒì„±
        create_table_sql = f"""
        CREATE TABLE {table_name} (
            id INT AUTO_INCREMENT PRIMARY KEY,
            stock_code VARCHAR(10) NOT NULL,
            stock_name VARCHAR(100) NOT NULL,
            themes JSON NOT NULL,
            price INT DEFAULT 0,
            change_rate DECIMAL(5,2) DEFAULT 0,
            volume BIGINT DEFAULT 0,
            news JSON NOT NULL,
            theme_stocks JSON NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            INDEX idx_stock_code (stock_code),
            INDEX idx_stock_name (stock_name)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        """

        cursor.execute(create_table_sql)
        print(f"   âœ… {table_name} í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

        cursor.close()
        connection.close()

        return table_name

    except Exception as e:
        print(f"   âŒ DB ì„¤ì • ì‹¤íŒ¨: {e}")
        if connection:
            connection.close()
        return False


def save_to_database(data, table_name):
    """í¬ë¡¤ë§ ë°ì´í„°ë¥¼ DBì— ì €ì¥"""
    print(f"\nğŸ’¾ DB ì €ì¥ ì‹œì‘ (í…Œì´ë¸”: {table_name})...")

    connection = get_db_connection()
    if not connection:
        return False

    try:
        cursor = connection.cursor()
        cursor.execute("USE crawling_db")

        # ì¢…ëª©ë³„ë¡œ ë°ì´í„° ì •ë¦¬ (ì¤‘ë³µ ì œê±°)
        stock_data = {}

        for theme_name, theme_data in data.items():
            theme_info = theme_data['theme_info']
            theme_stocks = theme_data['theme_stocks']  # í…Œë§ˆ ë‚´ ëª¨ë“  ì¢…ëª© ì •ë³´

            for stock in theme_data['stocks']:
                stock_code = stock['code']

                if stock_code not in stock_data:
                    stock_data[stock_code] = {
                        'stock_code': stock_code,
                        'stock_name': stock['name'],
                        'themes': [],
                        'price': stock['price'],
                        'change_rate': stock['change_rate'],
                        'volume': stock['volume'],
                        'news': stock['news'],
                        'theme_stocks': {}  # í…Œë§ˆë³„ ì¢…ëª© ì •ë³´
                    }

                # í…Œë§ˆ ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
                if theme_name not in stock_data[stock_code]['themes']:
                    stock_data[stock_code]['themes'].append(theme_name)

                # í•´ë‹¹ í…Œë§ˆì˜ ëª¨ë“  ì¢…ëª© ì •ë³´ ì¶”ê°€
                stock_data[stock_code]['theme_stocks'][theme_name] = theme_stocks

        # DBì— ì‚½ì…
        insert_sql = f"""
        INSERT INTO {table_name} (stock_code, stock_name, themes, price, change_rate, volume, news, theme_stocks)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
        """

        success_count = 0
        for stock_code, stock_info in stock_data.items():
            try:
                cursor.execute(insert_sql, (
                    stock_info['stock_code'],
                    stock_info['stock_name'],
                    json.dumps(stock_info['themes'], ensure_ascii=False),
                    stock_info['price'],
                    stock_info['change_rate'],
                    stock_info['volume'],
                    json.dumps(stock_info['news'], ensure_ascii=False),
                    json.dumps(stock_info['theme_stocks'], ensure_ascii=False)
                ))
                success_count += 1

                # ì €ì¥ëœ ë°ì´í„° ì¶œë ¥
                themes_str = ', '.join(stock_info['themes'])
                news_count = len(stock_info['news'])
                total_theme_stocks = sum(len(stocks) for stocks in stock_info['theme_stocks'].values())

                print(f"   ğŸ’¾ {stock_info['stock_name']} ({stock_code})")
                print(f"      ğŸ“‹ í…Œë§ˆ: {themes_str}")
                print(f"      ğŸ’° ê°€ê²©: {stock_info['price']:,}ì› ({stock_info['change_rate']:+.2f}%)")
                print(f"      ğŸ“° ë‰´ìŠ¤: {news_count}ê°œ")
                print(f"      ğŸ‘¥ í…Œë§ˆ ë‚´ ì¢…ëª©: {total_theme_stocks}ê°œ")

            except Exception as e:
                print(f"   âŒ {stock_info['stock_name']} ì €ì¥ ì‹¤íŒ¨: {e}")

        cursor.close()
        connection.close()

        print(f"\nâœ… DB ì €ì¥ ì™„ë£Œ: {success_count}/{len(stock_data)}ê°œ ì¢…ëª©")
        return True

    except Exception as e:
        print(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        if connection:
            connection.close()
        return False


def verify_database(table_name):
    """DB ì €ì¥ ê²°ê³¼ ê²€ì¦"""
    print(f"\nğŸ” DB ì €ì¥ ê²°ê³¼ ê²€ì¦ (í…Œì´ë¸”: {table_name})...")

    connection = get_db_connection()
    if not connection:
        return

    try:
        cursor = connection.cursor()
        cursor.execute("USE crawling_db")

        # ì´ ë ˆì½”ë“œ ìˆ˜
        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
        total_count = cursor.fetchone()[0]

        # í…Œë§ˆë³„ í†µê³„
        cursor.execute(f"""
        SELECT 
            JSON_UNQUOTE(JSON_EXTRACT(themes, '$[0]')) as first_theme,
            COUNT(*) as stock_count,
            AVG(change_rate) as avg_change_rate
        FROM {table_name}
        GROUP BY first_theme
        ORDER BY stock_count DESC
        """)

        theme_stats = cursor.fetchall()

        # ë‰´ìŠ¤ í†µê³„
        cursor.execute(f"""
        SELECT 
            AVG(JSON_LENGTH(news)) as avg_news_count,
            MIN(JSON_LENGTH(news)) as min_news_count,
            MAX(JSON_LENGTH(news)) as max_news_count
        FROM {table_name}
        """)

        news_stats = cursor.fetchone()

        # ìƒìœ„ 5ê°œ ì¢…ëª©
        cursor.execute(f"""
        SELECT stock_name, change_rate, JSON_LENGTH(news) as news_count
        FROM {table_name}
        ORDER BY change_rate DESC
        LIMIT 5
        """)

        top_stocks = cursor.fetchall()

        # í…Œë§ˆ ë‚´ ì¢…ëª© í†µê³„
        cursor.execute(f"""
        SELECT 
            AVG(JSON_LENGTH(theme_stocks)) as avg_theme_stocks,
            JSON_UNQUOTE(JSON_EXTRACT(JSON_KEYS(theme_stocks), '$[0]')) as sample_theme
        FROM {table_name}
        WHERE JSON_LENGTH(theme_stocks) > 0
        LIMIT 1
        """)

        theme_stocks_stats = cursor.fetchone()

        # ê²°ê³¼ ì¶œë ¥
        print(f"   ğŸ“Š ì´ ì¢…ëª© ìˆ˜: {total_count}ê°œ")
        print(f"   ğŸ“° í‰ê·  ë‰´ìŠ¤ ìˆ˜: {news_stats[0]:.1f}ê°œ (ìµœì†Œ: {news_stats[1]}ê°œ, ìµœëŒ€: {news_stats[2]}ê°œ)")

        if theme_stocks_stats and theme_stocks_stats[0]:
            print(f"   ğŸ‘¥ í‰ê·  í…Œë§ˆ ë‚´ ì¢…ëª© ìˆ˜: {theme_stocks_stats[0]:.1f}ê°œ")

        print(f"\n   ğŸ“‹ í…Œë§ˆë³„ ì¢…ëª© ìˆ˜:")
        for theme, count, avg_rate in theme_stats[:5]:  # ìƒìœ„ 5ê°œ í…Œë§ˆ
            print(f"      {theme}: {count}ê°œ ì¢…ëª© (í‰ê·  ë“±ë½ë¥ : {avg_rate:+.2f}%)")

        print(f"\n   ğŸ† ìƒìœ„ 5ê°œ ì¢…ëª©:")
        for i, (name, rate, news_count) in enumerate(top_stocks, 1):
            print(f"      {i}. {name}: {rate:+.2f}% ({news_count}ê°œ ë‰´ìŠ¤)")

        cursor.close()
        connection.close()

    except Exception as e:
        print(f"   âŒ DB ê²€ì¦ ì‹¤íŒ¨: {e}")
        if connection:
            connection.close()


# ê¸°ì¡´ í¬ë¡¤ë§ í•¨ìˆ˜ë“¤ (ê°„ì†Œí™” - DB ì €ì¥ ê´€ë ¨ ë¡œê·¸ë§Œ ì¶œë ¥)
def get_theme_list():
    """í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ (ë¡œê·¸ ìµœì†Œí™”)"""
    url = "https://finance.naver.com/sise/theme.naver"
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}

    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'euc-kr'
        soup = BeautifulSoup(response.text, 'html.parser')

        table = soup.find('table', {'class': 'type_1'})
        if not table:
            return []

        themes = []
        rows = table.find_all('tr')[1:]

        for row in rows:
            try:
                cols = row.find_all('td')
                if len(cols) < 4:
                    continue

                theme_link = cols[0].find('a')
                if not theme_link:
                    continue

                theme_name = clean_text(theme_link.text)
                theme_url = theme_link.get('href', '')
                theme_code_match = re.search(r'no=(\d+)', theme_url)
                theme_code = theme_code_match.group(1) if theme_code_match else ""
                change_rate = parse_percentage(cols[3].text)

                if theme_name and theme_code and change_rate > 0:
                    themes.append({
                        'name': theme_name,
                        'code': theme_code,
                        'change_rate': change_rate,
                        'url': f"https://finance.naver.com{theme_url}"
                    })
            except:
                continue

        return themes
    except:
        return []


def get_theme_stocks(theme_code, theme_name, limit=5):
    """íŠ¹ì • í…Œë§ˆì˜ ìƒìœ„ ì¢…ëª© í¬ë¡¤ë§ + í…Œë§ˆ ë‚´ ëª¨ë“  ì¢…ëª© ì •ë³´"""
    print(f"    ğŸ“ˆ {theme_name} ìƒìœ„ {limit}ê°œ ì¢…ëª© + ì „ì²´ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘...")

    url = f"https://finance.naver.com/sise/sise_group_detail.naver?type=theme&no={theme_code}"
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}

    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.encoding = 'euc-kr'
        soup = BeautifulSoup(response.text, 'html.parser')

        stock_links = soup.find_all('a', href=re.compile(r'/item/main\.naver\?code=\d{6}'))
        if not stock_links:
            return [], []

        # ëª¨ë“  ì¢…ëª© ì •ë³´ ìˆ˜ì§‘ (theme_stocksìš©)
        all_theme_stocks = []
        top_stocks = []  # ìƒìœ„ ì¢…ëª©ë“¤
        processed_codes = set()

        for link in stock_links:
            try:
                href = link.get('href', '')
                code_match = re.search(r'code=(\d{6})', href)
                if not code_match:
                    continue

                stock_code = code_match.group(1)
                if stock_code in processed_codes:
                    continue
                processed_codes.add(stock_code)

                stock_name = clean_text(link.text)
                if not stock_name or len(stock_name) < 2:
                    continue

                row = link.find_parent('tr')
                current_price = 0
                change_rate = 0
                volume = 0

                if row:
                    cells = row.find_all('td')
                    for cell in cells:
                        cell_text = clean_text(cell.text)

                        if cell_text.isdigit() and int(cell_text) >= 1000:
                            if current_price == 0:
                                current_price = int(cell_text)

                        if '%' in cell_text:
                            rate = parse_percentage(cell_text)
                            if abs(rate) < 100:
                                change_rate = rate

                        if cell_text.isdigit() and int(cell_text) > 10000:
                            if volume == 0 or int(cell_text) > volume:
                                volume = int(cell_text)

                # ëª¨ë“  ì¢…ëª© ì •ë³´ (theme_stocksìš©)
                theme_stock_info = {
                    'code': stock_code,
                    'name': stock_name,
                    'price': current_price,
                    'change_rate': change_rate,
                    'volume': volume
                }
                all_theme_stocks.append(theme_stock_info)

                # ìƒìœ„ ì¢…ëª©ë“¤ë§Œ ë”°ë¡œ ì €ì¥ (ë‰´ìŠ¤ ìˆ˜ì§‘ìš©)
                if len(top_stocks) < limit:
                    top_stocks.append({
                        'code': stock_code,
                        'name': stock_name,
                        'price': current_price,
                        'change_rate': change_rate,
                        'volume': volume
                    })

            except:
                continue

        print(f"    âœ… {theme_name}: ìƒìœ„ {len(top_stocks)}ê°œ ì¢…ëª©, ì „ì²´ {len(all_theme_stocks)}ê°œ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘")
        return top_stocks, all_theme_stocks

    except Exception as e:
        print(f"    âŒ {theme_name} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return [], []


def get_stock_news(stock_code, stock_name, limit=5):
    """íŠ¹ì • ì¢…ëª©ì˜ ë‰´ìŠ¤ í¬ë¡¤ë§ (ë‰´ìŠ¤ 5ê°œ)"""
    url = f"https://finance.naver.com/item/news_news.naver?code={stock_code}&page=1&sm=title_entity_id.basic&clusterId="
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Referer': f'https://finance.naver.com/item/main.naver?code={stock_code}'
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'euc-kr'
        soup = BeautifulSoup(response.text, 'html.parser')

        news_table = soup.find('table', {'class': 'type5'})
        if not news_table:
            return []

        news_list = []
        rows = news_table.find_all('tr')

        current_date = None
        today = datetime.now().date()
        yesterday = today - timedelta(days=1)

        for row in rows:
            try:
                date_cell = row.find('td', {'class': 'date'})
                if date_cell and date_cell.get('colspan'):
                    date_text = clean_text(date_cell.text)
                    current_date = parse_news_date(date_text)
                    continue

                title_cell = row.find('td', {'class': 'title'})
                if not title_cell:
                    continue

                news_link = title_cell.find('a')
                if not news_link:
                    continue

                title = clean_text(news_link.text)
                if not title:
                    continue

                news_url = news_link.get('href', '')
                if news_url and not news_url.startswith('http'):
                    news_url = urljoin('https://finance.naver.com', news_url)

                source_cell = row.find('td', {'class': 'info'})
                source = clean_text(source_cell.text) if source_cell else ""

                time_cell = row.find('td', {'class': 'date'})
                news_time = current_date
                if time_cell and not time_cell.get('colspan'):
                    time_text = clean_text(time_cell.text)
                    news_time = parse_news_time(time_text, current_date)

                if news_time and (news_time.date() == today or news_time.date() == yesterday):
                    news_data = {
                        'title': title,
                        'url': news_url,
                        'source': source,
                        'time': news_time.strftime('%Y-%m-%d %H:%M') if news_time else '',
                        'is_today': news_time.date() == today if news_time else False
                    }

                    news_list.append(news_data)

                    if len(news_list) >= limit:
                        break

            except:
                continue

        return news_list
    except:
        return []


def parse_news_date(date_text):
    """ë‰´ìŠ¤ ë‚ ì§œ íŒŒì‹±"""
    try:
        if '.' in date_text:
            date_parts = date_text.split('.')
            if len(date_parts) == 3:
                year = int(date_parts[0])
                month = int(date_parts[1])
                day = int(date_parts[2])
                return datetime(year, month, day)

        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

        if 'ì˜¤ëŠ˜' in date_text:
            return today
        elif 'ì–´ì œ' in date_text:
            return today - timedelta(days=1)

        return today
    except:
        return datetime.now()


def parse_news_time(time_text, base_date):
    """ë‰´ìŠ¤ ì‹œê°„ íŒŒì‹±"""
    try:
        if not base_date:
            base_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

        time_match = re.search(r'(\d{1,2}):(\d{2})', time_text)
        if time_match:
            hour = int(time_match.group(1))
            minute = int(time_match.group(2))
            return base_date.replace(hour=hour, minute=minute)

        return base_date
    except:
        return base_date


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë„¤ì´ë²„ ê¸ˆìœµ í…Œë§ˆ + ë‰´ìŠ¤ í¬ë¡¤ë§ + DB ì €ì¥ ì‹œì‘\n")

    # 1. DB ì„¤ì •
    table_name = setup_database()
    if not table_name:
        print("âŒ DB ì„¤ì • ì‹¤íŒ¨ - í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
        return

    # 2. í¬ë¡¤ë§ ì‹¤í–‰ (ë¡œê·¸ ìµœì†Œí™”)
    print("\nğŸ“¡ í¬ë¡¤ë§ ì‹œì‘...")
    themes = get_theme_list()

    if not themes:
        print("âŒ í¬ë¡¤ë§í•  í…Œë§ˆê°€ ì—†ìŠµë‹ˆë‹¤")
        return

    print(f"âœ… {len(themes)}ê°œ ìƒìŠ¹ í…Œë§ˆ ë°œê²¬")

    # 3. ë°ì´í„° ìˆ˜ì§‘ (ëª¨ë“  ìƒìŠ¹ í…Œë§ˆì˜ ìƒìœ„ 5ê°œ ì¢…ëª©)
    result = {}

    for i, theme in enumerate(themes):
        theme_name = theme['name']
        theme_code = theme['code']
        change_rate = theme['change_rate']

        print(f"[{i + 1}/{len(themes)}] {theme_name} (+{change_rate}%) ì²˜ë¦¬ ì¤‘...")

        # í•´ë‹¹ í…Œë§ˆì˜ ìƒìœ„ 5ê°œ ì¢…ëª© + ì „ì²´ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘
        top_stocks, all_theme_stocks = get_theme_stocks(theme_code, theme_name, limit=5)
        if not top_stocks:
            print(f"    âŒ {theme_name}: ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            continue

        print(f"    ğŸ“° ìƒìœ„ {len(top_stocks)}ê°œ ì¢…ëª©ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")

        # ìƒìœ„ 5ê°œ ì¢…ëª©ì˜ ë‰´ìŠ¤ë§Œ ìˆ˜ì§‘
        stocks_with_news = []
        for j, stock in enumerate(top_stocks):
            print(f"       [{j + 1}/{len(top_stocks)}] {stock['name']} ë‰´ìŠ¤ ìˆ˜ì§‘...")
            stock_news = get_stock_news(stock['code'], stock['name'], limit=5)

            stock_data = stock.copy()
            stock_data['news'] = stock_news
            stocks_with_news.append(stock_data)

            time.sleep(0.8)  # ì¢…ëª© ê°„ ìš”ì²­ ê°„ê²©

        result[theme_name] = {
            'theme_info': {
                'code': theme_code,
                'change_rate': change_rate
            },
            'stocks': stocks_with_news,
            'theme_stocks': all_theme_stocks  # í…Œë§ˆ ë‚´ ëª¨ë“  ì¢…ëª© ì •ë³´
        }

        total_news = sum(len(stock['news']) for stock in stocks_with_news)
        print(
            f"    âœ… {theme_name} ì™„ë£Œ: ìƒìœ„ {len(stocks_with_news)}ê°œ ì¢…ëª©, {total_news}ê°œ ë‰´ìŠ¤, í…Œë§ˆ ë‚´ {len(all_theme_stocks)}ê°œ ì¢…ëª© ì •ë³´")

        time.sleep(2)  # í…Œë§ˆ ê°„ ìš”ì²­ ê°„ê²©

    # 4. DB ì €ì¥
    if result:
        save_success = save_to_database(result, table_name)

        if save_success:
            # 5. DB ê²€ì¦
            verify_database(table_name)

        print(f"\nğŸ¯ ìµœì¢… ê²°ê³¼:")
        print(f"   ğŸ“Š í…Œì´ë¸”: {table_name}")
        print(f"   ğŸ“‹ í…Œë§ˆ: {len(result)}ê°œ")
        total_stocks = sum(len(data['stocks']) for data in result.values())
        total_news = sum(len(stock['news']) for data in result.values() for stock in data['stocks'])
        print(f"   ğŸ“ˆ ì´ ì¢…ëª©: {total_stocks}ê°œ")
        print(f"   ğŸ“° ì´ ë‰´ìŠ¤: {total_news}ê°œ")
        print(f"   âš¡ í‰ê·  ì¢…ëª©ë‹¹ ë‰´ìŠ¤: {total_news / total_stocks:.1f}ê°œ" if total_stocks > 0 else "")

        # í…Œë§ˆë³„ í†µê³„
        print(f"\nğŸ“Š í…Œë§ˆë³„ ìƒì„¸:")
        for theme_name, data in result.items():
            stock_count = len(data['stocks'])
            news_count = sum(len(stock['news']) for stock in data['stocks'])
            print(f"   {theme_name}: {stock_count}ê°œ ì¢…ëª©, {news_count}ê°œ ë‰´ìŠ¤")
    else:
        print("âŒ í¬ë¡¤ë§ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")


if __name__ == "__main__":
    main()