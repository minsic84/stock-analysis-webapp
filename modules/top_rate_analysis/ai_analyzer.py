#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import openai
import json
import logging
from typing import List, Dict, Optional
from datetime import datetime
import os

from .models import NewsData, StockData, SectorData, AIAnalysisResult, SupplyDemandData
from common.utils import clean_text


class AIAnalyzer:
    """OpenAI GPTë¥¼ ì´ìš©í•œ AI ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self, api_key: Optional[str] = None):
        """AI ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        openai.api_key = self.api_key

        # ë¶„ì„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.analysis_prompt_template = self._load_analysis_prompt()

    def analyze_stock_news(self, sectors: List[SectorData], news_dict: Dict[str, List[NewsData]]) -> AIAnalysisResult:
        """ì¢…ëª© ë‰´ìŠ¤ ì¢…í•© ë¶„ì„"""
        try:
            # ë¶„ì„ìš© ë°ì´í„° ì¤€ë¹„
            analysis_data = self._prepare_analysis_data(sectors, news_dict)

            # GPT í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_analysis_prompt(analysis_data)

            # OpenAI GPT í˜¸ì¶œ
            response = openai.ChatCompletion.create(
                model="gpt-4",  # ë˜ëŠ” "gpt-3.5-turbo"
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì¼ ë‰´ìŠ¤ì™€ ì¬ë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ì ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=2000,
                temperature=0.3,
                presence_penalty=0.1,
                frequency_penalty=0.1
            )

            # ì‘ë‹µ íŒŒì‹±
            analysis_text = response.choices[0].message.content
            analysis_result = self._parse_gpt_response(analysis_text)

            logging.info("AI ë¶„ì„ ì™„ë£Œ")
            return analysis_result

        except Exception as e:
            logging.error(f"AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._create_fallback_analysis()

    def analyze_supply_demand(self, supply_data: List[SupplyDemandData]) -> str:
        """ìˆ˜ê¸‰ ë°ì´í„° AI ë¶„ì„"""
        try:
            # ìˆ˜ê¸‰ ë°ì´í„° ìš”ì•½
            supply_summary = self._summarize_supply_data(supply_data)

            prompt = f"""
ë‹¤ìŒ ìˆ˜ê¸‰ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íˆ¬ì ê´€ì ì—ì„œ í•´ì„í•´ì£¼ì„¸ìš”:

{supply_summary}

ë¶„ì„ ìš”ì :
1. ì™¸êµ­ì¸ì˜ ì„ ì œì  ì›€ì§ì„ (ì˜ˆì§€ ëŠ¥ë ¥)
2. ê¸°ê´€ (ì‚¬ëª¨í€ë“œ, íˆ¬ì‹ ) ë™ì°¸ ì—¬ë¶€
3. ê°œì¸ íˆ¬ììì˜ ì—°ì°©ë§¤ìˆ˜ ìœ„í—˜ì„±
4. ì‹ ìš©ì”ê³  ê³¼ì—´ ì—¬ë¶€
5. ìˆ˜ê¸‰ ë‹¨ê³„ (ê¸°ë°˜â†’íˆ¬ì‹ â†’ê°œì¸) ì§„ë‹¨

200ì ì´ë‚´ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
"""

            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì£¼ì‹ ìˆ˜ê¸‰ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=300,
                temperature=0.2
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            logging.error(f"ìˆ˜ê¸‰ AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            return "ìˆ˜ê¸‰ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def _prepare_analysis_data(self, sectors: List[SectorData], news_dict: Dict[str, List[NewsData]]) -> Dict:
        """ë¶„ì„ìš© ë°ì´í„° ì¤€ë¹„"""
        analysis_data = {
            "sectors": [],
            "total_news": 0,
            "key_keywords": [],
            "today_materials": []
        }

        all_keywords = []

        for sector in sectors:
            sector_info = {
                "name": sector.sector_name,
                "change_rate": sector.change_rate,
                "stocks": []
            }

            for stock in sector.top_stocks:
                stock_news = news_dict.get(stock.stock_code, [])

                stock_info = {
                    "name": stock.stock_name,
                    "code": stock.stock_code,
                    "change_rate": stock.change_rate,
                    "news_count": len(stock_news),
                    "news_titles": [news.title for news in stock_news if news.is_today],
                    "keywords": []
                }

                # ë‰´ìŠ¤ í‚¤ì›Œë“œ ìˆ˜ì§‘
                for news in stock_news:
                    if news.is_today:  # ë‹¹ì¼ ë‰´ìŠ¤ë§Œ
                        stock_info["keywords"].extend(news.keywords)
                        all_keywords.extend(news.keywords)
                        analysis_data["today_materials"].append({
                            "stock": stock.stock_name,
                            "title": news.title,
                            "time": news.time_display,
                            "keywords": news.keywords
                        })

                sector_info["stocks"].append(stock_info)
                analysis_data["total_news"] += len([n for n in stock_news if n.is_today])

            analysis_data["sectors"].append(sector_info)

        # ì£¼ìš” í‚¤ì›Œë“œ ë¹ˆë„ ê³„ì‚°
        keyword_counts = {}
        for keyword in all_keywords:
            keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1

        # ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
        analysis_data["key_keywords"] = sorted(
            keyword_counts.items(),
            key=lambda x: x[1],
            reverse=True
        )[:10]

        return analysis_data

    def _create_analysis_prompt(self, data: Dict) -> str:
        """GPT ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = f"""
ì˜¤ëŠ˜({datetime.now().strftime('%Y-%m-%d')}) ì£¼ì‹ì‹œì¥ ë“±ë½ìœ¨ ìƒìœ„ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

## ğŸ“Š ìƒìœ„ ì—…ì¢… í˜„í™©
"""

        for sector in data["sectors"]:
            prompt += f"\n**{sector['name']}** ({sector['change_rate']:+.2f}%)\n"
            for stock in sector["stocks"]:
                if stock["news_count"] > 0:
                    prompt += f"- {stock['name']}: {stock['change_rate']:+.2f}%, ë‹¹ì¼ë‰´ìŠ¤ {stock['news_count']}ê±´\n"

        prompt += f"\n## ğŸ“° ì£¼ìš” ë‹¹ì¼ ì¬ë£Œ ({len(data['today_materials'])}ê±´)\n"

        for material in data["today_materials"][:10]:  # ìƒìœ„ 10ê°œë§Œ
            prompt += f"- **{material['stock']}**: {material['title']} ({material['time']})\n"

        prompt += f"\n## ğŸ”‘ í‚¤ì›Œë“œ ë¹ˆë„\n"
        for keyword, count in data["key_keywords"][:5]:
            prompt += f"- {keyword}: {count}íšŒ\n"

        prompt += f"""

## ğŸ¯ ë¶„ì„ ìš”ì²­ì‚¬í•­

ë‹¤ìŒ ê´€ì ì—ì„œ ì¢…í•© ë¶„ì„í•´ì£¼ì„¸ìš”:

### 1. í•µì‹¬ íˆ¬ì í¬ì¸íŠ¸ (ë‹¹ì¼ ì¬ë£Œ ì¤‘ì‹¬)
- ìƒˆë¡œìš´ í˜ì‹  ì¬ë£Œ (ì‹œëŒ€ê°œë§‰, AIí˜ì‹  ë“±)
- ê¸€ë¡œë²Œ ëŒ€ê¸°ì—… ì´ìŠˆ (íˆ¬ì, CEOë°œì–¸, í˜‘ì—…)
- ëŒ€ë°• ì‹¤ì  (100%+ ì¦ê°€, ê¸€ë¡œë²Œ ì§„ì¶œ)
- ì„¸ê³„ìµœì´ˆ/FDAìŠ¹ì¸/ì¡°ë‹¨ìœ„ ì´ìŠˆ
- ë³µí•© ì‹œë„ˆì§€ íš¨ê³¼

### 2. ìˆ˜ê¸‰ ì¢…í•© íŒë‹¨
- ì™¸êµ­ì¸ì˜ ì„ ì œì  ì›€ì§ì„ (ì˜ˆì§€ ëŠ¥ë ¥)
- ê¸°ê´€ (ì‚¬ëª¨í€ë“œ, íˆ¬ì‹ ) ë™ì°¸ë„
- ê°œì¸ ì—°ì°©ë§¤ìˆ˜ ìœ„í—˜ë„
- ìˆ˜ê¸‰ ë‹¨ê³„ ì§„ë‹¨

### 3. ìœ„í—˜ ìš”ì†Œ
- ê°œì¸ ì—°ì°©ë§¤ìˆ˜ ì§•í›„
- ì‹ ìš©ì”ê³  ê³¼ì—´ ê°€ëŠ¥ì„±
- ë‹¨ê¸° ì¡°ì • ë¦¬ìŠ¤í¬

### 4. íˆ¬ì ì „ëµ ì œì–¸
- ë‹¨ê¸° vs ì¤‘ì¥ê¸° ê´€ì 
- ì„¹í„° ë¡œí…Œì´ì…˜ ì „ë§
- íƒ€ì´ë° ì „ëµ

ì‘ë‹µ í˜•ì‹:
JSON í˜•íƒœë¡œ ë‹¤ìŒ êµ¬ì¡°ì— ë§ì¶° ë‹µë³€í•´ì£¼ì„¸ìš”:
{{
    "summary": "í•µì‹¬ ìš”ì•½ (2-3ë¬¸ì¥)",
    "key_points": ["í•µì‹¬í¬ì¸íŠ¸1", "í•µì‹¬í¬ì¸íŠ¸2", "í•µì‹¬í¬ì¸íŠ¸3"],
    "keywords": ["ì¶”ì¶œëœí‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
    "supply_analysis": "ìˆ˜ê¸‰ ë¶„ì„ ìš”ì•½",
    "risk_factors": ["ìœ„í—˜ìš”ì†Œ1", "ìœ„í—˜ìš”ì†Œ2"],
    "investment_recommendation": "íˆ¬ì ì „ëµ ì œì–¸",
    "confidence_score": 85
}}
"""

        return prompt

    def _parse_gpt_response(self, response_text: str) -> AIAnalysisResult:
        """GPT ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1

            if json_start >= 0 and json_end > json_start:
                json_text = response_text[json_start:json_end]
                analysis_json = json.loads(json_text)

                return AIAnalysisResult(
                    summary=analysis_json.get("summary", ""),
                    key_points=analysis_json.get("key_points", []),
                    keywords=analysis_json.get("keywords", []),
                    supply_analysis=analysis_json.get("supply_analysis", ""),
                    risk_factors=analysis_json.get("risk_factors", []),
                    investment_recommendation=analysis_json.get("investment_recommendation", ""),
                    confidence_score=analysis_json.get("confidence_score", 0.0)
                )
            else:
                # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                return AIAnalysisResult(
                    summary=response_text[:200],
                    key_points=[response_text],
                    keywords=["ë¶„ì„ì™„ë£Œ"],
                    confidence_score=50.0
                )

        except Exception as e:
            logging.error(f"GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._create_fallback_analysis()

    def _create_fallback_analysis(self) -> AIAnalysisResult:
        """ë¶„ì„ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ì‘ë‹µ"""
        return AIAnalysisResult(
            summary="AI ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ë‰´ìŠ¤ì™€ ìˆ˜ê¸‰ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
            key_points=[
                "ë‰´ìŠ¤ ì¬ë£Œ ì§ì ‘ í™•ì¸ í•„ìš”",
                "ìˆ˜ê¸‰ ë™í–¥ ëª¨ë‹ˆí„°ë§ í•„ìš”",
                "ê¸°ìˆ ì  ë¶„ì„ ë³‘í–‰ ê¶Œì¥"
            ],
            keywords=["ìˆ˜ë™ë¶„ì„"],
            supply_analysis="ìˆ˜ê¸‰ ë°ì´í„°ë¥¼ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.",
            risk_factors=["AI ë¶„ì„ ë¶ˆê°€"],
            investment_recommendation="ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.",
            confidence_score=0.0
        )

    def _summarize_supply_data(self, supply_data: List[SupplyDemandData]) -> str:
        """ìˆ˜ê¸‰ ë°ì´í„° ìš”ì•½"""
        if not supply_data:
            return "ìˆ˜ê¸‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ìµœê·¼ 5ì¼ ë°ì´í„° ìš”ì•½
        recent_data = supply_data[-5:] if len(supply_data) >= 5 else supply_data

        summary = "ìµœê·¼ ìˆ˜ê¸‰ í˜„í™©:\n"

        total_foreign = sum(d.foreign_net for d in recent_data)
        total_institution = sum(d.institution_net for d in recent_data)
        total_individual = sum(d.individual_net for d in recent_data)

        summary += f"- ì™¸êµ­ì¸: {total_foreign:+,}ì–µì›\n"
        summary += f"- ê¸°ê´€: {total_institution:+,}ì–µì›\n"
        summary += f"- ê°œì¸: {total_individual:+,}ì–µì›\n"

        if recent_data:
            latest = recent_data[-1]
            summary += f"- ìµœê·¼ ì‹ ìš©ì”ê³ : {latest.credit_balance:,}ì–µì›\n"

        return summary

    def _load_analysis_prompt(self) -> str:
        """ë¶„ì„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ"""
        return """
ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ì‹œì¥ì˜ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ë‹¹ì¼ ë°œìƒí•œ ë‰´ìŠ¤ì™€ ì¬ë£Œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ íˆ¬ì ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

íŠ¹íˆ ë‹¤ìŒ ìš”ì†Œë“¤ì„ ì¤‘ì ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤:
1. í˜ì‹  ì¬ë£Œì˜ ì„íŒ©íŠ¸
2. ê¸€ë¡œë²Œ ì´ìŠˆì˜ íŒŒê¸‰íš¨ê³¼  
3. ìˆ˜ê¸‰ íë¦„ì˜ ë³€í™”
4. ì‹œì¥ íƒ€ì´ë°ê³¼ ìœ„í—˜ ìš”ì†Œ

ë‹¹ì¼ì„±ê³¼ ì‹¤ì‹œê°„ì„±ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""

    def calculate_stock_score(self, stock: StockData, news_list: List[NewsData],
                              supply_data: Optional[SupplyDemandData] = None) -> int:
        """ê°œë³„ ì¢…ëª© ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        try:
            score = 50  # ê¸°ë³¸ ì ìˆ˜

            # 1. ë“±ë½ë¥  ì ìˆ˜ (30ì )
            if stock.change_rate > 10:
                score += 30
            elif stock.change_rate > 5:
                score += 20
            elif stock.change_rate > 0:
                score += 10

            # 2. ë‰´ìŠ¤ ì¬ë£Œ ì ìˆ˜ (25ì )
            today_news = [n for n in news_list if n.is_today]
            score += min(len(today_news) * 5, 15)  # ë‰´ìŠ¤ ê°œìˆ˜

            # í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤
            all_keywords = []
            for news in today_news:
                all_keywords.extend(news.keywords)

            premium_keywords = ['AI', 'ê¸€ë¡œë²ŒëŒ€ê¸°ì—…', 'FDAìŠ¹ì¸', 'ì¡°ë‹¨ìœ„ì´ìŠˆ']
            keyword_bonus = len(set(all_keywords) & set(premium_keywords)) * 2
            score += min(keyword_bonus, 10)

            # 3. ì‹ ê³ ê°€ ì ìˆ˜ (20ì )
            if stock.is_new_high_200d:
                score += 20
            elif stock.is_new_high_120d:
                score += 15
            elif stock.is_new_high_60d:
                score += 10
            elif stock.is_new_high_20d:
                score += 5

            # 4. ìˆ˜ê¸‰ ì ìˆ˜ (25ì )
            if supply_data:
                if supply_data.is_foreign_buying:
                    score += 10
                if supply_data.is_institution_buying:
                    score += 8
                if supply_data.is_individual_selling:
                    score += 7  # ê°œì¸ ë§¤ë„ëŠ” ê¸ì •ì 

            return min(score, 100)  # ìµœëŒ€ 100ì 

        except Exception as e:
            logging.error(f"ì¢…ëª© ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 50