#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ë“±ë½ìœ¨ìƒìœ„ë¶„ì„ ì „ìš© ë°ì´í„°ë² ì´ìŠ¤ í´ë˜ìŠ¤
- ì™„ì „ ë…ë¦½ì ì¸ DB ì—°ê²° ë° ê´€ë¦¬
- ë‚ ì§œë³„ í…Œì´ë¸” ìë™ ìƒì„±/ê´€ë¦¬
- í¬ë¡¤ë§ ë°ì´í„° ì €ì¥ ë° ì¡°íšŒ
"""

import pymysql
import json
import logging
from datetime import datetime
from typing import List, Dict, Optional, Tuple
import os
from .utils import get_trading_date, get_table_name


class TopRateDatabase:
    """ë“±ë½ìœ¨ìƒìœ„ë¶„ì„ ì „ìš© ë°ì´í„°ë² ì´ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì • ì´ˆê¸°í™”"""
        self.db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': int(os.getenv('DB_PORT', 3306)),
            'user': os.getenv('DB_USER', 'stock_user'),
            'password': os.getenv('DB_PASSWORD', 'StockPass2025!'),
            'charset': 'utf8mb4',
            'autocommit': True
        }

        # ì „ìš© í¬ë¡¤ë§ ë°ì´í„°ë² ì´ìŠ¤
        self.crawling_db = 'crawling_db'

        # ì—°ê²° í…ŒìŠ¤íŠ¸
        self._test_connection()

    def _test_connection(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            connection = self.get_connection()
            connection.close()
            logging.info("âœ… TopRateDatabase ì—°ê²° ì„±ê³µ")
            return True
        except Exception as e:
            logging.error(f"âŒ TopRateDatabase ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def get_connection(self, database: str = None) -> pymysql.Connection:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë°˜í™˜

        Args:
            database: ì—°ê²°í•  ë°ì´í„°ë² ì´ìŠ¤ëª… (Noneì´ë©´ ê¸°ë³¸ ì—°ê²°)

        Returns:
            pymysql.Connection ê°ì²´
        """
        config = self.db_config.copy()
        if database:
            config['database'] = database
        return pymysql.connect(**config)

    def setup_crawling_database(self) -> bool:
        """
        í¬ë¡¤ë§ ì „ìš© ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            connection = self.get_connection()
            cursor = connection.cursor()

            # ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´)
            cursor.execute(
                f"CREATE DATABASE IF NOT EXISTS {self.crawling_db} "
                "CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci"
            )

            cursor.close()
            connection.close()

            logging.info(f"âœ… í¬ë¡¤ë§ ë°ì´í„°ë² ì´ìŠ¤ ({self.crawling_db}) ì„¤ì • ì™„ë£Œ")
            return True

        except Exception as e:
            logging.error(f"âŒ í¬ë¡¤ë§ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False

    def setup_theme_table(self, date_str: str) -> str:
        """
        ë‚ ì§œë³„ í…Œë§ˆ í…Œì´ë¸” ìƒì„± (ê¸°ì¡´ í…Œì´ë¸” ë®ì–´ì“°ê¸°)

        Args:
            date_str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ

        Returns:
            ìƒì„±ëœ í…Œì´ë¸”ëª…
        """
        table_name = get_table_name(date_str)

        try:
            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ (ë®ì–´ì“°ê¸°)
            cursor.execute(f"DROP TABLE IF EXISTS {table_name}")

            # ìƒˆ í…Œì´ë¸” ìƒì„±
            create_sql = f"""
            CREATE TABLE {table_name} (
                id INT AUTO_INCREMENT PRIMARY KEY,
                stock_code VARCHAR(10) NOT NULL,
                stock_name VARCHAR(100) NOT NULL,
                price INT DEFAULT 0,
                change_rate DECIMAL(5,2) DEFAULT 0.00,
                volume BIGINT DEFAULT 0,
                themes JSON,
                news JSON,
                theme_stocks JSON,
                crawled_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_stock_code (stock_code),
                INDEX idx_change_rate (change_rate),
                INDEX idx_crawled_at (crawled_at)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """

            cursor.execute(create_sql)
            cursor.close()
            connection.close()

            logging.info(f"âœ… í…Œë§ˆ í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {table_name}")
            return table_name

        except Exception as e:
            logging.error(f"âŒ í…Œë§ˆ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def save_theme_data(self, table_name: str, theme_data: List[Dict]) -> bool:
        """
        í…Œë§ˆ í¬ë¡¤ë§ ë°ì´í„° ì €ì¥

        Args:
            table_name: ì €ì¥í•  í…Œì´ë¸”ëª…
            theme_data: ì €ì¥í•  í…Œë§ˆ ë°ì´í„° ë¦¬ìŠ¤íŠ¸

        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        if not theme_data:
            logging.warning("ì €ì¥í•  í…Œë§ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False

        try:
            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            insert_sql = f"""
            INSERT INTO {table_name} 
            (stock_code, stock_name, price, change_rate, volume, themes, news, theme_stocks)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """

            success_count = 0

            for data in theme_data:
                try:
                    cursor.execute(insert_sql, (
                        data.get('stock_code', ''),
                        data.get('stock_name', ''),
                        data.get('price', 0),
                        data.get('change_rate', 0.0),
                        data.get('volume', 0),
                        json.dumps(data.get('themes', []), ensure_ascii=False),
                        json.dumps(data.get('news', []), ensure_ascii=False),
                        json.dumps(data.get('theme_stocks', {}), ensure_ascii=False)
                    ))
                    success_count += 1

                except Exception as e:
                    logging.error(f"ê°œë³„ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ ({data.get('stock_name', 'Unknown')}): {e}")
                    continue

            cursor.close()
            connection.close()

            logging.info(f"âœ… í…Œë§ˆ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {success_count}/{len(theme_data)}ê°œ")
            return success_count > 0

        except Exception as e:
            logging.error(f"âŒ í…Œë§ˆ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def get_theme_data(self, date_str: str) -> List[Dict]:
        """
        ë‚ ì§œë³„ í…Œë§ˆ ë°ì´í„° ì¡°íšŒ

        Args:
            date_str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ

        Returns:
            í…Œë§ˆ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        table_name = get_table_name(date_str)

        try:
            if not self.check_table_exists(table_name):
                logging.warning(f"í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {table_name}")
                return []

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor(pymysql.cursors.DictCursor)

            query = f"""
            SELECT stock_code, stock_name, price, change_rate, volume, 
                   themes, news, theme_stocks, crawled_at
            FROM {table_name} 
            ORDER BY change_rate DESC
            """

            cursor.execute(query)
            results = cursor.fetchall()

            # JSON í•„ë“œ íŒŒì‹±
            for result in results:
                for json_field in ['themes', 'news', 'theme_stocks']:
                    if result[json_field]:
                        try:
                            result[json_field] = json.loads(result[json_field])
                        except json.JSONDecodeError:
                            result[json_field] = []

            cursor.close()
            connection.close()

            logging.info(f"âœ… í…Œë§ˆ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {len(results)}ê°œ ({table_name})")
            return results

        except Exception as e:
            logging.error(f"âŒ í…Œë§ˆ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def get_theme_summary(self, date_str: str) -> List[Dict]:
        """
        í…Œë§ˆë³„ ìš”ì•½ í†µê³„ ì¡°íšŒ (ë¶„ì„ìš©)

        Args:
            date_str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ

        Returns:
            í…Œë§ˆë³„ ìš”ì•½ ë°ì´í„°
        """
        table_name = get_table_name(date_str)

        try:
            if not self.check_table_exists(table_name):
                logging.warning(f"í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {table_name}")
                return []

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor(pymysql.cursors.DictCursor)

            # í…Œë§ˆë³„ ì§‘ê³„ ì¿¼ë¦¬ (JSON ë°°ì—´ì˜ ì²« ë²ˆì§¸ í…Œë§ˆ ê¸°ì¤€)
            query = f"""
            SELECT 
                JSON_UNQUOTE(JSON_EXTRACT(themes, '$[0]')) as theme_name,
                COUNT(*) as stock_count,
                ROUND(AVG(change_rate), 2) as avg_change_rate,
                ROUND(MAX(change_rate), 2) as max_change_rate,
                SUM(CASE WHEN change_rate > 0 THEN 1 ELSE 0 END) as rising_stocks,
                SUM(JSON_LENGTH(news)) as total_news,
                (
                    SELECT CONCAT(stock_name, ' (+', ROUND(change_rate, 1), '%)')
                    FROM {table_name} t2
                    WHERE JSON_EXTRACT(t2.themes, '$[0]') = JSON_EXTRACT({table_name}.themes, '$[0]')
                    ORDER BY change_rate DESC 
                    LIMIT 1
                ) as top_stock,
                GROUP_CONCAT(
                    CONCAT(stock_name, ':', ROUND(change_rate, 1), '%') 
                    ORDER BY change_rate DESC 
                    SEPARATOR '|'
                ) as all_stocks
            FROM {table_name}
            WHERE JSON_LENGTH(themes) > 0 
            AND JSON_UNQUOTE(JSON_EXTRACT(themes, '$[0]')) IS NOT NULL
            AND JSON_UNQUOTE(JSON_EXTRACT(themes, '$[0]')) != ''
            GROUP BY JSON_UNQUOTE(JSON_EXTRACT(themes, '$[0]'))
            HAVING theme_name IS NOT NULL
            ORDER BY avg_change_rate DESC
            """

            cursor.execute(query)
            results = cursor.fetchall()

            # ì•„ì´ì½˜ ë§¤í•‘ ì¶”ê°€
            icon_mapping = {
                'ì¦ê¶Œ': 'ğŸ¦', 'AIë°˜ë„ì²´': 'ğŸ¤–', '2ì°¨ì „ì§€': 'ğŸ”‹',
                'ë°”ì´ì˜¤': 'ğŸ§¬', 'ê²Œì„': 'ğŸ®', 'ìë™ì°¨': 'ğŸš—',
                'í™”í•™': 'âš—ï¸', 'ì¡°ì„ ': 'ğŸš¢', 'í•­ê³µ': 'âœˆï¸',
                'ê±´ì„¤': 'ğŸ—ï¸', 'í†µì‹ ': 'ğŸ“¡', 'ì€í–‰': 'ğŸ›ï¸',
                'ë°˜ë„ì²´': 'ğŸ’¾', 'í—¬ìŠ¤ì¼€ì–´': 'ğŸ¥', 'ì—”í„°í…Œì¸ë¨¼íŠ¸': 'ğŸ­',
                'ì½”ë¡œë‚˜19': 'ğŸ¦ ', 'K-pop': 'ğŸµ', 'ë©”íƒ€ë²„ìŠ¤': 'ğŸŒ',
                'ì „ê¸°ì°¨': 'âš¡', 'ì¹œí™˜ê²½': 'ğŸŒ±', 'ìš°ì£¼í•­ê³µ': 'ğŸš€',
                'ë¡œë´‡': 'ğŸ¤–', 'VR/AR': 'ğŸ¥½', 'ë¸”ë¡ì²´ì¸': 'â›“ï¸'
            }

            # ê²°ê³¼ ê°€ê³µ
            for result in results:
                result['icon'] = icon_mapping.get(result['theme_name'], 'ğŸ“Š')
                result['rising_ratio'] = (
                    result['rising_stocks'] / result['stock_count'] * 100
                    if result['stock_count'] > 0 else 0
                )

            cursor.close()
            connection.close()

            logging.info(f"âœ… í…Œë§ˆ ìš”ì•½ ì¡°íšŒ ì™„ë£Œ: {len(results)}ê°œ í…Œë§ˆ ({date_str})")
            return results

        except Exception as e:
            logging.error(f"âŒ í…Œë§ˆ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def get_theme_detail(self, date_str: str, theme_name: str) -> Dict:
        """
        íŠ¹ì • í…Œë§ˆì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ

        Args:
            date_str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ
            theme_name: í…Œë§ˆëª…

        Returns:
            í…Œë§ˆ ìƒì„¸ ì •ë³´
        """
        table_name = get_table_name(date_str)

        try:
            if not self.check_table_exists(table_name):
                return {}

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor(pymysql.cursors.DictCursor)

            # í•´ë‹¹ í…Œë§ˆ ì¢…ëª©ë“¤ ì¡°íšŒ
            query = f"""
            SELECT stock_code, stock_name, price, change_rate, volume, news
            FROM {table_name}
            WHERE JSON_CONTAINS(themes, JSON_QUOTE(%s))
            ORDER BY change_rate DESC
            """

            cursor.execute(query, (theme_name,))
            stocks = cursor.fetchall()

            # JSON í•„ë“œ íŒŒì‹±
            all_news = []
            for stock in stocks:
                if stock['news']:
                    try:
                        stock_news = json.loads(stock['news'])
                        all_news.extend(stock_news)
                        stock['news'] = stock_news
                    except json.JSONDecodeError:
                        stock['news'] = []

            cursor.close()
            connection.close()

            if not stocks:
                return {}

            # í…Œë§ˆ í†µê³„ ê³„ì‚°
            change_rates = [stock['change_rate'] for stock in stocks]
            rising_count = len([rate for rate in change_rates if rate > 0])

            result = {
                'theme_name': theme_name,
                'stock_count': len(stocks),
                'avg_change_rate': sum(change_rates) / len(change_rates),
                'max_change_rate': max(change_rates),
                'rising_stocks': rising_count,
                'total_news': len(all_news),
                'stocks': stocks,
                'news': all_news[:10]  # ìƒìœ„ 10ê°œ ë‰´ìŠ¤ë§Œ
            }

            logging.info(f"âœ… í…Œë§ˆ ìƒì„¸ì •ë³´ ì¡°íšŒ ì™„ë£Œ: {theme_name} ({len(stocks)}ê°œ ì¢…ëª©)")
            return result

        except Exception as e:
            logging.error(f"âŒ í…Œë§ˆ ìƒì„¸ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def check_table_exists(self, table_name: str) -> bool:
        """
        í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸

        Args:
            table_name: í™•ì¸í•  í…Œì´ë¸”ëª…

        Returns:
            ì¡´ì¬ ì—¬ë¶€
        """
        try:
            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            cursor.execute(f"SHOW TABLES LIKE '{table_name}'")
            exists = cursor.fetchone() is not None

            cursor.close()
            connection.close()

            return exists

        except Exception as e:
            logging.error(f"í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

    def get_available_dates(self) -> List[str]:
        """
        ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ìˆëŠ” ë‚ ì§œ ëª©ë¡ ì¡°íšŒ

        Returns:
            ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ (YYYY-MM-DD í˜•ì‹)
        """
        try:
            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            cursor.execute("SHOW TABLES LIKE 'theme_%'")
            tables = cursor.fetchall()

            cursor.close()
            connection.close()

            # í…Œì´ë¸”ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
            dates = []
            for (table_name,) in tables:
                if table_name.startswith('theme_') and len(table_name) == 14:  # theme_YYYYMMDD
                    date_part = table_name[6:]  # YYYYMMDD
                    try:
                        # YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        formatted_date = f"{date_part[:4]}-{date_part[4:6]}-{date_part[6:8]}"
                        dates.append(formatted_date)
                    except:
                        continue

            dates.sort(reverse=True)  # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬
            return dates

        except Exception as e:
            logging.error(f"ë‚ ì§œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def delete_old_data(self, keep_days: int = 30) -> bool:
        """
        ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ (ë³´ê´€ ê¸°ê°„ ì´ˆê³¼)

        Args:
            keep_days: ë³´ê´€í•  ì¼ìˆ˜

        Returns:
            ì‚­ì œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            from datetime import timedelta

            cutoff_date = datetime.now() - timedelta(days=keep_days)
            cutoff_str = cutoff_date.strftime('%Y%m%d')

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            # ì‚­ì œ ëŒ€ìƒ í…Œì´ë¸” ì¡°íšŒ
            cursor.execute("SHOW TABLES LIKE 'theme_%'")
            tables = cursor.fetchall()

            deleted_count = 0
            for (table_name,) in tables:
                if table_name.startswith('theme_') and len(table_name) == 14:
                    date_part = table_name[6:]  # YYYYMMDD
                    if date_part < cutoff_str:
                        cursor.execute(f"DROP TABLE {table_name}")
                        deleted_count += 1
                        logging.info(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ í…Œì´ë¸” ì‚­ì œ: {table_name}")

            cursor.close()
            connection.close()

            if deleted_count > 0:
                logging.info(f"âœ… ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {deleted_count}ê°œ í…Œì´ë¸” ì‚­ì œ")
            else:
                logging.info("â„¹ï¸ ì‚­ì œí•  ì˜¤ë˜ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

            return True

        except Exception as e:
            logging.error(f"âŒ ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False

    def get_crawling_status(self, date_str: str) -> Dict:
        """
        í¬ë¡¤ë§ ìƒíƒœ ì •ë³´ ì¡°íšŒ

        Args:
            date_str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ

        Returns:
            í¬ë¡¤ë§ ìƒíƒœ ì •ë³´
        """
        table_name = get_table_name(date_str)

        try:
            if not self.check_table_exists(table_name):
                return {
                    'exists': False,
                    'total_stocks': 0,
                    'last_updated': None,
                    'theme_count': 0
                }

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor(pymysql.cursors.DictCursor)

            # ê¸°ë³¸ í†µê³„
            cursor.execute(f"SELECT COUNT(*) as total FROM {table_name}")
            total_result = cursor.fetchone()

            # ìµœê·¼ ì—…ë°ì´íŠ¸ ì‹œê°„
            cursor.execute(f"SELECT MAX(crawled_at) as last_updated FROM {table_name}")
            time_result = cursor.fetchone()

            # í…Œë§ˆ ìˆ˜
            cursor.execute(f"""
                SELECT COUNT(DISTINCT JSON_UNQUOTE(JSON_EXTRACT(themes, '$[0]'))) as theme_count
                FROM {table_name}
                WHERE JSON_LENGTH(themes) > 0
            """)
            theme_result = cursor.fetchone()

            cursor.close()
            connection.close()

            return {
                'exists': True,
                'total_stocks': total_result['total'] if total_result else 0,
                'last_updated': time_result['last_updated'] if time_result else None,
                'theme_count': theme_result['theme_count'] if theme_result else 0
            }

        except Exception as e:
            logging.error(f"âŒ í¬ë¡¤ë§ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'exists': False,
                'total_stocks': 0,
                'last_updated': None,
                'theme_count': 0
            }

    def get_theme_statistics(self, date_str: str) -> List[Dict]:
        """
        íŠ¹ì • ë‚ ì§œì˜ í…Œë§ˆë³„ í†µê³„ ì¡°íšŒ

        Args:
            date_str: ë‚ ì§œ (YYYY-MM-DD)

        Returns:
            í…Œë§ˆë³„ í†µê³„ ë¦¬ìŠ¤íŠ¸
        """
        try:
            table_name = get_table_name(date_str)

            if not self.table_exists(table_name):
                logging.warning(f"í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {table_name}")
                return []

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            # í…Œë§ˆë³„ ê¸°ë³¸ í†µê³„ ì¡°íšŒ
            query = f"""
            SELECT 
                theme_name,
                COUNT(*) as stock_count,
                AVG(CAST(change_rate AS DECIMAL(10,2))) as avg_change_rate,
                AVG(CAST(volume_ratio AS DECIMAL(10,2))) as avg_volume_ratio,
                SUM(CAST(volume AS BIGINT)) as total_volume,
                SUM(CASE WHEN CAST(change_rate AS DECIMAL(10,2)) > 0 THEN 1 ELSE 0 END) as positive_stocks
            FROM {table_name}
            WHERE theme_name IS NOT NULL 
                AND theme_name != ''
            GROUP BY theme_name
            ORDER BY avg_change_rate DESC
            """

            cursor.execute(query)
            results = cursor.fetchall()

            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            themes = []
            for row in results:
                theme_data = {
                    'theme_name': row[0],
                    'stock_count': row[1] or 0,
                    'avg_change_rate': float(row[2]) if row[2] else 0.0,
                    'avg_volume_ratio': float(row[3]) if row[3] else 0.0,
                    'total_volume': int(row[4]) if row[4] else 0,
                    'positive_stocks': row[5] or 0
                }
                themes.append(theme_data)

            cursor.close()
            connection.close()

            logging.info(f"í…Œë§ˆ í†µê³„ ì¡°íšŒ ì™„ë£Œ: {len(themes)}ê°œ í…Œë§ˆ")
            return themes

        except Exception as e:
            logging.error(f"í…Œë§ˆ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def get_theme_detail(self, date_str: str, theme_name: str) -> Dict:
        """
        íŠ¹ì • í…Œë§ˆì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ

        Args:
            date_str: ë‚ ì§œ (YYYY-MM-DD)
            theme_name: í…Œë§ˆëª…

        Returns:
            í…Œë§ˆ ìƒì„¸ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        try:
            table_name = get_table_name(date_str)

            if not self.table_exists(table_name):
                logging.warning(f"í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {table_name}")
                return {}

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            # í•´ë‹¹ í…Œë§ˆì˜ ëª¨ë“  ì¢…ëª© ì¡°íšŒ
            query = f"""
            SELECT 
                stock_code,
                stock_name,
                current_price,
                change_rate,
                volume,
                volume_ratio,
                market_cap,
                crawled_at
            FROM {table_name}
            WHERE theme_name = %s
            ORDER BY CAST(change_rate AS DECIMAL(10,2)) DESC
            """

            cursor.execute(query, (theme_name,))
            results = cursor.fetchall()

            if not results:
                cursor.close()
                connection.close()
                return {}

            # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
            stocks = []
            for row in results:
                stock_data = {
                    'stock_code': row[0],
                    'stock_name': row[1],
                    'current_price': int(row[2]) if row[2] else 0,
                    'change_rate': float(row[3]) if row[3] else 0.0,
                    'volume': int(row[4]) if row[4] else 0,
                    'volume_ratio': float(row[5]) if row[5] else 0.0,
                    'market_cap': int(row[6]) if row[6] else 0,
                    'crawled_at': row[7]
                }
                stocks.append(stock_data)

            # í…Œë§ˆ ìš”ì•½ í†µê³„
            total_stocks = len(stocks)
            avg_change_rate = sum(s['change_rate'] for s in stocks) / total_stocks if total_stocks > 0 else 0
            positive_stocks = len([s for s in stocks if s['change_rate'] > 0])
            total_volume = sum(s['volume'] for s in stocks)

            theme_detail = {
                'theme_name': theme_name,
                'date': date_str,
                'summary': {
                    'total_stocks': total_stocks,
                    'avg_change_rate': avg_change_rate,
                    'positive_stocks': positive_stocks,
                    'positive_ratio': (positive_stocks / total_stocks * 100) if total_stocks > 0 else 0,
                    'total_volume': total_volume
                },
                'stocks': stocks,
                'news': []  # ë‰´ìŠ¤ëŠ” ë³„ë„ êµ¬í˜„ í•„ìš”
            }

            cursor.close()
            connection.close()

            logging.info(f"í…Œë§ˆ ìƒì„¸ì •ë³´ ì¡°íšŒ ì™„ë£Œ: {theme_name} ({total_stocks}ê°œ ì¢…ëª©)")
            return theme_detail

        except Exception as e:
            logging.error(f"í…Œë§ˆ ìƒì„¸ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def has_date_data(self, date_str: str) -> bool:
        """
        íŠ¹ì • ë‚ ì§œì˜ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸

        Args:
            date_str: ë‚ ì§œ (YYYY-MM-DD)

        Returns:
            ë°ì´í„° ì¡´ì¬ ì—¬ë¶€
        """
        try:
            table_name = get_table_name(date_str)

            if not self.table_exists(table_name):
                return False

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            # ë°ì´í„° ê°œìˆ˜ í™•ì¸
            query = f"SELECT COUNT(*) FROM {table_name}"
            cursor.execute(query)
            count = cursor.fetchone()[0]

            cursor.close()
            connection.close()

            return count > 0

        except Exception as e:
            logging.error(f"ë°ì´í„° ì¡´ì¬ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

    def get_crawling_status(self, date_str: str) -> Dict:
        """
        íŠ¹ì • ë‚ ì§œì˜ í¬ë¡¤ë§ ìƒíƒœ ì •ë³´ ì¡°íšŒ

        Args:
            date_str: ë‚ ì§œ (YYYY-MM-DD)

        Returns:
            í¬ë¡¤ë§ ìƒíƒœ ì •ë³´
        """
        try:
            table_name = get_table_name(date_str)

            # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            table_exists = self.table_exists(table_name)

            if not table_exists:
                return {
                    'exists': False,
                    'table_name': table_name,
                    'total_stocks': 0,
                    'total_themes': 0,
                    'last_update': None,
                    'is_complete': False
                }

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            # ê¸°ë³¸ í†µê³„ ì¡°íšŒ
            stats_query = f"""
            SELECT 
                COUNT(*) as total_stocks,
                COUNT(DISTINCT theme_name) as total_themes,
                MAX(crawled_at) as last_update
            FROM {table_name}
            WHERE theme_name IS NOT NULL AND theme_name != ''
            """

            cursor.execute(stats_query)
            stats = cursor.fetchone()

            total_stocks = stats[0] or 0
            total_themes = stats[1] or 0
            last_update = stats[2]

            # ì™„ë£Œ ì—¬ë¶€ íŒë‹¨ (ì„ê³„ê°’ ê¸°ì¤€)
            is_complete = total_stocks >= 100 and total_themes >= 10

            cursor.close()
            connection.close()

            return {
                'exists': True,
                'table_name': table_name,
                'total_stocks': total_stocks,
                'total_themes': total_themes,
                'last_update': last_update,
                'is_complete': is_complete
            }

        except Exception as e:
            logging.error(f"í¬ë¡¤ë§ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'exists': False,
                'table_name': table_name if 'table_name' in locals() else '',
                'total_stocks': 0,
                'total_themes': 0,
                'last_update': None,
                'is_complete': False,
                'error': str(e)
            }