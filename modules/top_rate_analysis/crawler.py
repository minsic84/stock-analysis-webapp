#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ë„¤ì´ë²„ ê¸ˆìœµ í…Œë§ˆ í¬ë¡¤ëŸ¬ (theme_crawler_test.py ê¸°ë°˜)
í…Œë§ˆë³„ ìƒìœ„ ì¢…ëª©ì˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì—¬ DBì— ì €ì¥
"""

import requests
from bs4 import BeautifulSoup
import time
import re
from datetime import datetime, timedelta
from urllib.parse import urljoin
import logging
from typing import List, Dict

from modules.top_rate_analysis.utils import clean_text, parse_percentage, parse_news_date, parse_news_time
from .database import TopRateDatabase


class ThemeCrawler:
    """í…Œë§ˆ í¬ë¡¤ë§ í´ë˜ìŠ¤ (theme_crawler_test.py ê¸°ë°˜)"""

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        })
        self.db = TopRateDatabase()

    def crawl_and_save_themes(self, target_date: str) -> bool:
        """í…Œë§ˆ í¬ë¡¤ë§ í›„ DB ì €ì¥ (ë©”ì¸ í•¨ìˆ˜)"""
        try:
            logging.info(f"ğŸš€ {target_date} í…Œë§ˆ í¬ë¡¤ë§ ì‹œì‘...")

            # 1. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
            self.db.setup_crawling_database()
            table_name = self.db.setup_theme_table(target_date)

            # 2. í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§
            themes = self.get_theme_list()
            if not themes:
                logging.error("í¬ë¡¤ë§í•  í…Œë§ˆê°€ ì—†ìŠµë‹ˆë‹¤")
                return False

            logging.info(f"âœ… {len(themes)}ê°œ ìƒìŠ¹ í…Œë§ˆ ë°œê²¬")

            # 3. í…Œë§ˆë³„ ë°ì´í„° ìˆ˜ì§‘
            result = {}
            for i, theme in enumerate(themes):
                try:
                    theme_name = theme['name']
                    theme_code = theme['code']
                    change_rate = theme['change_rate']

                    logging.info(f"[{i + 1}/{len(themes)}] {theme_name} (+{change_rate}%) ì²˜ë¦¬ ì¤‘...")

                    # í…Œë§ˆë³„ ìƒìœ„ 5ê°œ ì¢…ëª© + ì „ì²´ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘
                    top_stocks, all_theme_stocks = self.get_theme_stocks(theme_code, theme_name, limit=5)
                    if not top_stocks:
                        logging.warning(f"{theme_name}: ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        continue

                    logging.info(f"    ğŸ“° ìƒìœ„ {len(top_stocks)}ê°œ ì¢…ëª©ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")

                    # ìƒìœ„ 5ê°œ ì¢…ëª©ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘
                    stocks_with_news = []
                    for j, stock in enumerate(top_stocks):
                        logging.info(f"       [{j + 1}/{len(top_stocks)}] {stock['name']} ë‰´ìŠ¤ ìˆ˜ì§‘...")
                        stock_news = self.get_stock_news(stock['code'], stock['name'], limit=5)

                        stock_data = stock.copy()
                        stock_data['news'] = stock_news
                        stocks_with_news.append(stock_data)

                        time.sleep(0.8)  # ì¢…ëª© ê°„ ìš”ì²­ ê°„ê²©

                    result[theme_name] = {
                        'theme_info': {
                            'code': theme_code,
                            'change_rate': change_rate
                        },
                        'stocks': stocks_with_news,
                        'theme_stocks': all_theme_stocks
                    }

                    total_news = sum(len(stock['news']) for stock in stocks_with_news)
                    logging.info(f"    âœ… {theme_name} ì™„ë£Œ: ìƒìœ„ {len(stocks_with_news)}ê°œ ì¢…ëª©, {total_news}ê°œ ë‰´ìŠ¤")

                    time.sleep(2)  # í…Œë§ˆ ê°„ ìš”ì²­ ê°„ê²©

                except Exception as e:
                    logging.error(f"í…Œë§ˆ {theme.get('name', 'Unknown')} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue

            # 4. DB ì €ì¥
            if result:
                success = self.db.save_theme_data(table_name, result)
                if success:
                    logging.info(f"ğŸ¯ {target_date} í…Œë§ˆ í¬ë¡¤ë§ ì™„ë£Œ!")
                    self._print_crawling_summary(result)
                    return True
                else:
                    logging.error("DB ì €ì¥ ì‹¤íŒ¨")
                    return False
            else:
                logging.error("í¬ë¡¤ë§ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False

        except Exception as e:
            logging.error(f"í…Œë§ˆ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return False

    def get_theme_list(self) -> List[Dict]:
        """í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§"""
        url = "https://finance.naver.com/sise/theme.naver"

        try:
            response = requests.get(url, headers=self.session.headers, timeout=10)
            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')

            table = soup.find('table', {'class': 'type_1'})
            if not table:
                return []

            themes = []
            rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸

            for row in rows:
                try:
                    cols = row.find_all('td')
                    if len(cols) < 4:
                        continue

                    theme_link = cols[0].find('a')
                    if not theme_link:
                        continue

                    theme_name = clean_text(theme_link.text)
                    theme_url = theme_link.get('href', '')
                    theme_code_match = re.search(r'no=(\d+)', theme_url)
                    theme_code = theme_code_match.group(1) if theme_code_match else ""
                    change_rate = parse_percentage(cols[3].text)

                    if theme_name and theme_code and change_rate > 0:
                        themes.append({
                            'name': theme_name,
                            'code': theme_code,
                            'change_rate': change_rate,
                            'url': f"https://finance.naver.com{theme_url}"
                        })
                except Exception as e:
                    logging.error(f"í…Œë§ˆ íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

            return themes

        except Exception as e:
            logging.error(f"í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return []

    def get_theme_stocks(self, theme_code: str, theme_name: str, limit: int = 5) -> tuple:
        """íŠ¹ì • í…Œë§ˆì˜ ìƒìœ„ ì¢…ëª© í¬ë¡¤ë§ + í…Œë§ˆ ë‚´ ëª¨ë“  ì¢…ëª© ì •ë³´"""
        url = f"https://finance.naver.com/sise/sise_group_detail.naver?type=theme&no={theme_code}"

        try:
            response = requests.get(url, headers=self.session.headers, timeout=15)
            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')

            stock_links = soup.find_all('a', href=re.compile(r'/item/main\.naver\?code=\d{6}'))
            if not stock_links:
                return [], []

            # ëª¨ë“  ì¢…ëª© ì •ë³´ ìˆ˜ì§‘
            all_theme_stocks = []
            top_stocks = []
            processed_codes = set()

            for link in stock_links:
                try:
                    href = link.get('href', '')
                    code_match = re.search(r'code=(\d{6})', href)
                    if not code_match:
                        continue

                    stock_code = code_match.group(1)
                    if stock_code in processed_codes:
                        continue
                    processed_codes.add(stock_code)

                    stock_name = clean_text(link.text)
                    if not stock_name or len(stock_name) < 2:
                        continue

                    row = link.find_parent('tr')
                    current_price = 0
                    change_rate = 0
                    volume = 0

                    if row:
                        cells = row.find_all('td')
                        for cell in cells:
                            cell_text = clean_text(cell.text)

                            if cell_text.isdigit() and int(cell_text) >= 1000:
                                if current_price == 0:
                                    current_price = int(cell_text)

                            if '%' in cell_text:
                                rate = parse_percentage(cell_text)
                                if abs(rate) < 100:
                                    change_rate = rate

                            if cell_text.isdigit() and int(cell_text) > 10000:
                                if volume == 0 or int(cell_text) > volume:
                                    volume = int(cell_text)

                    # ëª¨ë“  ì¢…ëª© ì •ë³´
                    theme_stock_info = {
                        'code': stock_code,
                        'name': stock_name,
                        'price': current_price,
                        'change_rate': change_rate,
                        'volume': volume
                    }
                    all_theme_stocks.append(theme_stock_info)

                    # ìƒìœ„ ì¢…ëª©ë“¤ë§Œ ë”°ë¡œ ì €ì¥
                    if len(top_stocks) < limit:
                        top_stocks.append({
                            'code': stock_code,
                            'name': stock_name,
                            'price': current_price,
                            'change_rate': change_rate,
                            'volume': volume
                        })

                except Exception as e:
                    logging.error(f"ì¢…ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

            logging.info(f"    âœ… {theme_name}: ìƒìœ„ {len(top_stocks)}ê°œ ì¢…ëª©, ì „ì²´ {len(all_theme_stocks)}ê°œ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘")
            return top_stocks, all_theme_stocks

        except Exception as e:
            logging.error(f"í…Œë§ˆ ì¢…ëª© í¬ë¡¤ë§ ì‹¤íŒ¨ ({theme_name}): {e}")
            return [], []

    def get_stock_news(self, stock_code: str, stock_name: str, limit: int = 5) -> List[Dict]:
        """íŠ¹ì • ì¢…ëª©ì˜ ë‰´ìŠ¤ í¬ë¡¤ë§"""
        url = f"https://finance.naver.com/item/news_news.naver?code={stock_code}&page=1&sm=title_entity_id.basic&clusterId="

        try:
            response = requests.get(url, headers=self.session.headers, timeout=10)
            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')

            news_table = soup.find('table', {'class': 'type5'})
            if not news_table:
                return []

            news_list = []
            rows = news_table.find_all('tr')

            current_date = None
            today = datetime.now().date()
            yesterday = today - timedelta(days=1)

            for row in rows:
                try:
                    # ë‚ ì§œ í–‰ í™•ì¸
                    date_cell = row.find('td', {'class': 'date'})
                    if date_cell and date_cell.get('colspan'):
                        date_text = clean_text(date_cell.text)
                        current_date = parse_news_date(date_text)
                        continue

                    # ë‰´ìŠ¤ ì œëª© í–‰
                    title_cell = row.find('td', {'class': 'title'})
                    if not title_cell:
                        continue

                    news_link = title_cell.find('a')
                    if not news_link:
                        continue

                    title = clean_text(news_link.text)
                    if not title:
                        continue

                    news_url = news_link.get('href', '')
                    if news_url and not news_url.startswith('http'):
                        news_url = urljoin('https://finance.naver.com', news_url)

                    # ë‰´ìŠ¤ ì¶œì²˜
                    source_cell = row.find('td', {'class': 'info'})
                    source = clean_text(source_cell.text) if source_cell else ""

                    # ì‹œê°„ ì •ë³´
                    time_cell = row.find('td', {'class': 'date'})
                    news_time = current_date
                    if time_cell and not time_cell.get('colspan'):
                        time_text = clean_text(time_cell.text)
                        news_time = parse_news_time(time_text, current_date)

                    # ë‹¹ì¼ ë˜ëŠ” ì–´ì œ ë‰´ìŠ¤ë§Œ
                    if news_time and (news_time.date() == today or news_time.date() == yesterday):
                        news_data = {
                            'title': title,
                            'url': news_url,
                            'source': source,
                            'time': news_time.strftime('%Y-%m-%d %H:%M') if news_time else '',
                            'is_today': news_time.date() == today if news_time else False
                        }

                        news_list.append(news_data)

                        if len(news_list) >= limit:
                            break

                except Exception as e:
                    logging.error(f"ë‰´ìŠ¤ íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

            return news_list

        except Exception as e:
            logging.error(f"ì¢…ëª© ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤íŒ¨ ({stock_name}): {e}")
            return []

    def _print_crawling_summary(self, result: Dict):
        """í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        total_themes = len(result)
        total_stocks = sum(len(data['stocks']) for data in result.values())
        total_news = sum(len(stock['news']) for data in result.values() for stock in data['stocks'])

        logging.info(f"\nğŸ¯ í¬ë¡¤ë§ ìµœì¢… ê²°ê³¼:")
        logging.info(f"   ğŸ“Š í…Œë§ˆ: {total_themes}ê°œ")
        logging.info(f"   ğŸ“ˆ ì´ ì¢…ëª©: {total_stocks}ê°œ")
        logging.info(f"   ğŸ“° ì´ ë‰´ìŠ¤: {total_news}ê°œ")
        logging.info(f"   âš¡ í‰ê·  ì¢…ëª©ë‹¹ ë‰´ìŠ¤: {total_news / total_stocks:.1f}ê°œ" if total_stocks > 0 else "")

        logging.info(f"\nğŸ“Š í…Œë§ˆë³„ ìƒì„¸:")
        for theme_name, data in result.items():
            stock_count = len(data['stocks'])
            news_count = sum(len(stock['news']) for stock in data['stocks'])
            logging.info(f"   {theme_name}: {stock_count}ê°œ ì¢…ëª©, {news_count}ê°œ ë‰´ìŠ¤")