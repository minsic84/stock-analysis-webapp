#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ë“±ë½ìœ¨ìƒìœ„ë¶„ì„ í¬ë¡¤ëŸ¬ (ì‘ë™í•˜ëŠ” paste.txt ê¸°ë°˜ìœ¼ë¡œ ì™„ì „ ì¬ì‘ì„±)
- ë„¤ì´ë²„ ê¸ˆìœµ í…Œë§ˆë³„ ìƒìœ„ ì¢…ëª© í¬ë¡¤ë§
- ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© ì¶”ì 
- ì¢…ëª©ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘
"""

import requests
from bs4 import BeautifulSoup
import time
import re
import json
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Callable
from urllib.parse import urljoin

from .database import TopRateDatabase
from .utils import get_trading_date


class TopRateCrawler:
    """ë“±ë½ìœ¨ìƒìœ„ë¶„ì„ í¬ë¡¤ëŸ¬ (ì‘ë™ ê²€ì¦ëœ ì½”ë“œ ê¸°ë°˜)"""

    def __init__(self, progress_callback: Optional[Callable] = None):
        """í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”"""
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })

        self.db = TopRateDatabase()
        self.progress_callback = progress_callback

        # í¬ë¡¤ë§ ì„¤ì •
        self.max_stocks_per_theme = 5  # í…Œë§ˆë‹¹ ìµœëŒ€ ì¢…ëª© ìˆ˜
        self.news_per_stock = 5  # ì¢…ëª©ë‹¹ ë‰´ìŠ¤ ìˆ˜
        self.request_delay = 0.8  # ìš”ì²­ ê°„ ì§€ì—°ì‹œê°„
        self.theme_delay = 2.0  # í…Œë§ˆ ê°„ ì§€ì—°ì‹œê°„

    def crawl_and_save(self, target_date: Optional[str] = None) -> bool:
        """ì „ì²´ í¬ë¡¤ë§ ë° ì €ì¥ í”„ë¡œì„¸ìŠ¤"""
        start_time = datetime.now()

        if target_date is None:
            target_date = get_trading_date()

        logging.info(f"ğŸš€ ë“±ë½ìœ¨ìƒìœ„ë¶„ì„ í¬ë¡¤ë§ ì‹œì‘ (ë‚ ì§œ: {target_date})")

        try:
            # 1ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
            self._update_progress(5, "ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì¤‘...")
            self.db.setup_crawling_database()
            table_name = self.db.setup_theme_table(target_date)

            # 2ë‹¨ê³„: í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§
            self._update_progress(10, "í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ì¤‘...")
            themes = self._get_theme_list()

            if not themes:
                logging.error("âŒ í¬ë¡¤ë§í•  í…Œë§ˆê°€ ì—†ìŠµë‹ˆë‹¤")
                return False

            logging.info(f"âœ… {len(themes)}ê°œ ìƒìŠ¹ í…Œë§ˆ ë°œê²¬")

            # 3ë‹¨ê³„: í…Œë§ˆë³„ ë°ì´í„° ìˆ˜ì§‘
            result = {}
            total_themes = len(themes)

            for i, theme in enumerate(themes):
                try:
                    # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                    progress = 15 + (70 * i / total_themes)  # 15% ~ 85%
                    message = f"{theme['name']} í…Œë§ˆ ë¶„ì„ ì¤‘... ({i + 1}/{total_themes})"
                    self._update_progress(progress, message)

                    logging.info(f"[{i + 1}/{total_themes}] {theme['name']} (+{theme['change_rate']}%) ì²˜ë¦¬ ì¤‘...")

                    # í…Œë§ˆë³„ ì¢…ëª© + ë‰´ìŠ¤ ìˆ˜ì§‘
                    theme_data = self._process_theme(theme)

                    if theme_data:
                        result[theme['name']] = theme_data
                        stocks_count = len(theme_data['stocks'])
                        total_news = sum(len(stock['news']) for stock in theme_data['stocks'])
                        logging.info(f"    âœ… {theme['name']} ì™„ë£Œ: {stocks_count}ê°œ ì¢…ëª©, {total_news}ê°œ ë‰´ìŠ¤")
                    else:
                        logging.warning(f"    âŒ {theme['name']}: ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")

                    # í…Œë§ˆ ê°„ ì§€ì—°
                    time.sleep(self.theme_delay)

                except Exception as e:
                    logging.error(f"    âŒ {theme['name']} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue

            if not result:
                logging.error("âŒ í¬ë¡¤ë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False

            # 4ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            self._update_progress(90, "ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")

            # ë°ì´í„° ë³€í™˜ (ê¸°ì¡´ DB ì €ì¥ í˜•ì‹ì— ë§ê²Œ)
            converted_data = self._convert_data_format(result)
            success = self.db.save_theme_data(table_name, converted_data)

            if success:
                self._update_progress(100, "í¬ë¡¤ë§ ì™„ë£Œ!")
                self._print_summary(result, target_date)

                end_time = datetime.now()
                duration = (end_time - start_time).total_seconds()
                logging.info(f"âš¡ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ: {duration:.1f}ì´ˆ ì†Œìš”")

                return True
            else:
                logging.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨")
                return False

        except Exception as e:
            logging.error(f"âŒ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
            return False

    def _get_theme_list(self) -> List[Dict]:
        """í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ (ì‘ë™ ê²€ì¦ëœ ì½”ë“œ)"""
        url = "https://finance.naver.com/sise/theme.naver"

        try:
            response = self.session.get(url, timeout=10)
            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')

            table = soup.find('table', {'class': 'type_1'})
            if not table:
                return []

            themes = []
            rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸

            for row in rows:
                try:
                    cols = row.find_all('td')
                    if len(cols) < 4:
                        continue

                    theme_link = cols[0].find('a')
                    if not theme_link:
                        continue

                    theme_name = self._clean_text(theme_link.text)
                    theme_url = theme_link.get('href', '')
                    theme_code_match = re.search(r'no=(\d+)', theme_url)
                    theme_code = theme_code_match.group(1) if theme_code_match else ""
                    change_rate = self._parse_percentage(cols[3].text)

                    if theme_name and theme_code and change_rate > 0:
                        themes.append({
                            'name': theme_name,
                            'code': theme_code,
                            'change_rate': change_rate,
                            'url': f"https://finance.naver.com{theme_url}"
                        })

                except Exception:
                    continue

            return themes

        except Exception as e:
            logging.error(f"í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return []

    def _process_theme(self, theme: Dict) -> Optional[Dict]:
        """í…Œë§ˆë³„ ì¢…ëª© + ë‰´ìŠ¤ ì²˜ë¦¬ (ì‘ë™ ê²€ì¦ëœ ì½”ë“œ)"""
        theme_name = theme['name']
        theme_code = theme['code']

        # ì¢…ëª© ì •ë³´ ìˆ˜ì§‘
        top_stocks, all_theme_stocks = self._get_theme_stocks(theme_code, theme_name)
        if not top_stocks:
            return None

        # ë‰´ìŠ¤ ìˆ˜ì§‘
        stocks_with_news = []
        for j, stock in enumerate(top_stocks):
            logging.info(f"       [{j + 1}/{len(top_stocks)}] {stock['name']} ë‰´ìŠ¤ ìˆ˜ì§‘...")
            stock_news = self._get_stock_news(stock['code'], stock['name'])

            stock_data = stock.copy()
            stock_data['news'] = stock_news
            stocks_with_news.append(stock_data)

            time.sleep(self.request_delay)  # ì¢…ëª© ê°„ ì§€ì—°

        return {
            'theme_info': {
                'code': theme_code,
                'change_rate': theme['change_rate']
            },
            'stocks': stocks_with_news,
            'theme_stocks': all_theme_stocks
        }

    def _get_theme_stocks(self, theme_code: str, theme_name: str) -> tuple:
        """í…Œë§ˆë³„ ì¢…ëª© ìˆ˜ì§‘ (ì‘ë™ ê²€ì¦ëœ ì½”ë“œ)"""
        url = f"https://finance.naver.com/sise/sise_group_detail.naver?type=theme&no={theme_code}"

        try:
            response = self.session.get(url, timeout=15)
            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')

            stock_links = soup.find_all('a', href=re.compile(r'/item/main\.naver\?code=\d{6}'))
            if not stock_links:
                return [], []

            all_theme_stocks = []
            top_stocks = []
            processed_codes = set()

            for link in stock_links:
                try:
                    href = link.get('href', '')
                    code_match = re.search(r'code=(\d{6})', href)
                    if not code_match:
                        continue

                    stock_code = code_match.group(1)
                    if stock_code in processed_codes:
                        continue
                    processed_codes.add(stock_code)

                    stock_name = self._clean_text(link.text)
                    if not stock_name or len(stock_name) < 2:
                        continue

                    # ê°€ê²©/ë“±ë½ë¥ /ê±°ë˜ëŸ‰ ì¶”ì¶œ
                    row = link.find_parent('tr')
                    current_price = 0
                    change_rate = 0
                    volume = 0

                    if row:
                        cells = row.find_all('td')
                        for cell in cells:
                            cell_text = self._clean_text(cell.text)

                            # ê°€ê²© (1000 ì´ìƒ ìˆ«ì)
                            if cell_text.isdigit() and int(cell_text) >= 1000:
                                if current_price == 0:
                                    current_price = int(cell_text)

                            # ë“±ë½ë¥  (% í¬í•¨)
                            if '%' in cell_text:
                                rate = self._parse_percentage(cell_text)
                                if abs(rate) < 100:
                                    change_rate = rate

                            # ê±°ë˜ëŸ‰ (í° ìˆ«ì)
                            if cell_text.isdigit() and int(cell_text) > 10000:
                                if volume == 0 or int(cell_text) > volume:
                                    volume = int(cell_text)

                    stock_info = {
                        'code': stock_code,
                        'name': stock_name,
                        'price': current_price,
                        'change_rate': change_rate,
                        'volume': volume
                    }

                    all_theme_stocks.append(stock_info)

                    # ìƒìœ„ ì¢…ëª©ë§Œ ë”°ë¡œ ì €ì¥
                    if len(top_stocks) < self.max_stocks_per_theme:
                        top_stocks.append(stock_info)

                except Exception:
                    continue

            return top_stocks, all_theme_stocks

        except Exception as e:
            logging.error(f"í…Œë§ˆ ì¢…ëª© ìˆ˜ì§‘ ì‹¤íŒ¨ ({theme_name}): {e}")
            return [], []

    def _get_stock_news(self, stock_code: str, stock_name: str) -> List[Dict]:
        """ì¢…ëª©ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ (ì‘ë™ ê²€ì¦ëœ ì½”ë“œ)"""
        url = f"https://finance.naver.com/item/news_news.naver?code={stock_code}&page=1&sm=title_entity_id.basic&clusterId="
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Referer': f'https://finance.naver.com/item/main.naver?code={stock_code}'
        }

        try:
            response = requests.get(url, headers=headers, timeout=10)
            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')

            news_table = soup.find('table', {'class': 'type5'})
            if not news_table:
                return []

            news_list = []
            rows = news_table.find_all('tr')

            current_date = None
            today = datetime.now().date()
            yesterday = today - timedelta(days=1)

            for row in rows:
                try:
                    # ë‚ ì§œ í—¤ë” ì²˜ë¦¬
                    date_cell = row.find('td', {'class': 'date'})
                    if date_cell and date_cell.get('colspan'):
                        date_text = self._clean_text(date_cell.text)
                        current_date = self._parse_news_date(date_text)
                        continue

                    # ë‰´ìŠ¤ ì œëª© ì¶”ì¶œ
                    title_cell = row.find('td', {'class': 'title'})
                    if not title_cell:
                        continue

                    news_link = title_cell.find('a')
                    if not news_link:
                        continue

                    title = self._clean_text(news_link.text)
                    if not title:
                        continue

                    news_url = news_link.get('href', '')
                    if news_url and not news_url.startswith('http'):
                        news_url = urljoin('https://finance.naver.com', news_url)

                    # ì¶œì²˜ ì¶”ì¶œ
                    source_cell = row.find('td', {'class': 'info'})
                    source = self._clean_text(source_cell.text) if source_cell else ""

                    # ì‹œê°„ ì¶”ì¶œ
                    time_cell = row.find('td', {'class': 'date'})
                    news_time = current_date
                    if time_cell and not time_cell.get('colspan'):
                        time_text = self._clean_text(time_cell.text)
                        news_time = self._parse_news_time(time_text, current_date)

                    # ë‹¹ì¼/ì „ì¼ ë‰´ìŠ¤ë§Œ ìˆ˜ì§‘
                    if news_time and (news_time.date() == today or news_time.date() == yesterday):
                        news_data = {
                            'title': title,
                            'url': news_url,
                            'source': source,
                            'time': news_time.strftime('%Y-%m-%d %H:%M') if news_time else '',
                            'is_today': news_time.date() == today if news_time else False
                        }

                        news_list.append(news_data)

                        if len(news_list) >= self.news_per_stock:
                            break

                except Exception:
                    continue

            return news_list

        except Exception as e:
            logging.warning(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨ ({stock_name}): {e}")
            return []

    def _convert_data_format(self, result: Dict) -> List[Dict]:
        """í¬ë¡¤ë§ ê²°ê³¼ë¥¼ DB ì €ì¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        converted_data = []

        # ì¢…ëª©ë³„ë¡œ ë°ì´í„° ì •ë¦¬ (ì¤‘ë³µ ì œê±°)
        stock_data = {}

        for theme_name, theme_data in result.items():
            for stock in theme_data['stocks']:
                stock_code = stock['code']

                if stock_code not in stock_data:
                    stock_data[stock_code] = {
                        'stock_code': stock_code,
                        'stock_name': stock['name'],
                        'themes': [],
                        'price': stock['price'],
                        'change_rate': stock['change_rate'],
                        'volume': stock['volume'],
                        'news': stock['news'],
                        'theme_stocks': {}
                    }

                # í…Œë§ˆ ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
                if theme_name not in stock_data[stock_code]['themes']:
                    stock_data[stock_code]['themes'].append(theme_name)

                # í…Œë§ˆë³„ ì¢…ëª© ì •ë³´ ì¶”ê°€
                stock_data[stock_code]['theme_stocks'][theme_name] = theme_data['theme_stocks']

        # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        converted_data = list(stock_data.values())

        return converted_data

    def _update_progress(self, percent: float, message: str):
        """ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸"""
        if self.progress_callback:
            self.progress_callback(percent, message)
        logging.info(f"ğŸ”„ [{percent:.1f}%] {message}")

    def _print_summary(self, result: Dict, target_date: str):
        """í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        total_themes = len(result)
        total_stocks = sum(len(data['stocks']) for data in result.values())
        total_news = sum(len(stock['news']) for data in result.values() for stock in data['stocks'])

        logging.info(f"""
ğŸ¯ í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ ({target_date})
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š ì´ í…Œë§ˆ: {total_themes}ê°œ
ğŸ“ˆ ì´ ì¢…ëª©: {total_stocks}ê°œ  
ğŸ“° ì´ ë‰´ìŠ¤: {total_news}ê°œ
âš¡ í‰ê·  ë‰´ìŠ¤/ì¢…ëª©: {total_news / total_stocks:.1f}ê°œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”""")

    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ì‘ë™ ê²€ì¦ëœ ì½”ë“œ)
    def _clean_text(self, text):
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not text:
            return ""
        return text.strip().replace('\n', '').replace('\t', '').replace('\xa0', '').replace(',', '')

    def _parse_percentage(self, text):
        """í¼ì„¼íŠ¸ íŒŒì‹±"""
        if not text:
            return 0
        try:
            match = re.search(r'([+-]?\d+\.?\d*)%?', str(text))
            if match:
                return float(match.group(1))
            return 0
        except:
            return 0

    def _parse_news_date(self, date_text):
        """ë‰´ìŠ¤ ë‚ ì§œ íŒŒì‹±"""
        try:
            if '.' in date_text:
                date_parts = date_text.split('.')
                if len(date_parts) == 3:
                    year = int(date_parts[0])
                    month = int(date_parts[1])
                    day = int(date_parts[2])
                    return datetime(year, month, day)

            today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

            if 'ì˜¤ëŠ˜' in date_text:
                return today
            elif 'ì–´ì œ' in date_text:
                return today - timedelta(days=1)

            return today
        except:
            return datetime.now()

    def _parse_news_time(self, time_text, base_date):
        """ë‰´ìŠ¤ ì‹œê°„ íŒŒì‹±"""
        try:
            if not base_date:
                base_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

            time_match = re.search(r'(\d{1,2}):(\d{2})', time_text)
            if time_match:
                hour = int(time_match.group(1))
                minute = int(time_match.group(2))
                return base_date.replace(hour=hour, minute=minute)

            return base_date
        except:
            return base_date


# ì§„í–‰ìƒí™© ì¶”ì ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ (ì›¹ ì¸í„°í˜ì´ìŠ¤ìš©)
crawling_progress = {
    'is_running': False,
    'percent': 0,
    'message': '',
    'start_time': None,
    'end_time': None,
    'success': None,
    'error_message': ''
}