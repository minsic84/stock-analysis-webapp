#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ë“±ë½ìœ¨ìƒìœ„ë¶„ì„ í¬ë¡¤ëŸ¬ (theme_crawler_test.py ê¸°ë°˜)
- ë„¤ì´ë²„ ê¸ˆìœµ í…Œë§ˆë³„ ìƒìœ„ ì¢…ëª© í¬ë¡¤ë§
- ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© ì¶”ì 
- ì¢…ëª©ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘
"""

import requests
from bs4 import BeautifulSoup
import time
import re
import json
import logging
from datetime import datetime
from typing import List, Dict, Optional, Callable
from urllib.parse import urljoin

from .database import TopRateDatabase
from .utils import (
    get_trading_date, clean_text, parse_percentage,
    parse_number, safe_request, get_default_headers,
    format_progress_message, log_performance
)


class TopRateCrawler:
    """ë“±ë½ìœ¨ìƒìœ„ë¶„ì„ í¬ë¡¤ëŸ¬"""

    def __init__(self, progress_callback: Optional[Callable] = None):
        """
        í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”

        Args:
            progress_callback: ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜ (percent, message)
        """
        self.session = requests.Session()
        self.session.headers.update(get_default_headers())

        self.db = TopRateDatabase()
        self.progress_callback = progress_callback

        # í¬ë¡¤ë§ ì„¤ì •
        self.max_stocks_per_theme = 5  # í…Œë§ˆë‹¹ ìµœëŒ€ ì¢…ëª© ìˆ˜
        self.request_delay = 0.5  # ìš”ì²­ ê°„ ì§€ì—°ì‹œê°„ (ì´ˆ)
        self.max_retry = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

    def crawl_and_save(self, target_date: Optional[str] = None) -> bool:
        """
        ì „ì²´ í¬ë¡¤ë§ ë° ì €ì¥ í”„ë¡œì„¸ìŠ¤

        Args:
            target_date: ëŒ€ìƒ ë‚ ì§œ (Noneì´ë©´ ê±°ë˜ì¼ ê¸°ì¤€ ìë™ ê³„ì‚°)

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        start_time = datetime.now()

        if target_date is None:
            target_date = get_trading_date()

        logging.info(f"ğŸš€ ë“±ë½ìœ¨ìƒìœ„ë¶„ì„ í¬ë¡¤ë§ ì‹œì‘ (ë‚ ì§œ: {target_date})")

        try:
            # 1ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
            self._update_progress(5, "ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì¤‘...")
            self.db.setup_crawling_database()
            table_name = self.db.setup_theme_table(target_date)

            # 2ë‹¨ê³„: í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§
            self._update_progress(10, "í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ì¤‘...")
            themes = self._get_theme_list()

            if not themes:
                logging.error("âŒ í¬ë¡¤ë§í•  í…Œë§ˆê°€ ì—†ìŠµë‹ˆë‹¤")
                return False

            logging.info(f"âœ… {len(themes)}ê°œ ìƒìŠ¹ í…Œë§ˆ ë°œê²¬")

            # 3ë‹¨ê³„: í…Œë§ˆë³„ ì¢…ëª© í¬ë¡¤ë§
            self._update_progress(15, f"{len(themes)}ê°œ í…Œë§ˆ ë¶„ì„ ì‹œì‘...")
            all_stock_data = []

            for i, theme in enumerate(themes):
                try:
                    progress = 15 + (70 * (i + 1) / len(themes))  # 15% ~ 85%
                    message = f"{theme['name']} í…Œë§ˆ ë¶„ì„ ì¤‘... ({i + 1}/{len(themes)})"
                    self._update_progress(progress, message)

                    # í…Œë§ˆë³„ ì¢…ëª© í¬ë¡¤ë§
                    theme_stocks = self._get_theme_stocks(
                        theme['code'],
                        theme['name'],
                        limit=self.max_stocks_per_theme
                    )

                    if theme_stocks:
                        all_stock_data.extend(theme_stocks)
                        logging.info(f"  âœ… {theme['name']}: {len(theme_stocks)}ê°œ ì¢…ëª©")

                    # ìš”ì²­ ê°„ ì§€ì—°
                    time.sleep(self.request_delay)

                except Exception as e:
                    logging.error(f"  âŒ {theme['name']} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
                    continue

            if not all_stock_data:
                logging.error("âŒ í¬ë¡¤ë§ëœ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤")
                return False

            # 4ë‹¨ê³„: ì¢…ëª©ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘
            self._update_progress(85, f"{len(all_stock_data)}ê°œ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
            self._collect_stock_news(all_stock_data)

            # 5ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            self._update_progress(95, "ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")
            success = self.db.save_theme_data(table_name, all_stock_data)

            if success:
                self._update_progress(100, "í¬ë¡¤ë§ ì™„ë£Œ!")
                self._print_crawling_summary(all_stock_data, target_date)

                # ì„±ëŠ¥ ë¡œê·¸
                end_time = datetime.now()
                log_performance("ì „ì²´ í¬ë¡¤ë§", start_time, end_time, len(all_stock_data))

                return True
            else:
                logging.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨")
                return False

        except Exception as e:
            logging.error(f"âŒ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
            return False

    def _get_theme_list(self) -> List[Dict]:
        """
        ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ìƒìŠ¹ í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§

        Returns:
            í…Œë§ˆ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        url = "https://finance.naver.com/sise/theme.naver"

        for attempt in range(self.max_retry):
            try:
                response = safe_request(url, timeout=10)
                if not response:
                    continue

                response.encoding = 'euc-kr'
                soup = BeautifulSoup(response.text, 'html.parser')

                table = soup.find('table', {'class': 'type_1'})
                if not table:
                    logging.warning("í…Œë§ˆ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    continue

                themes = []
                rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸

                for row in rows:
                    try:
                        cols = row.find_all('td')
                        if len(cols) < 4:
                            continue

                        theme_link = cols[0].find('a')
                        if not theme_link:
                            continue

                        theme_name = clean_text(theme_link.text)
                        theme_url = theme_link.get('href', '')
                        theme_code_match = re.search(r'no=(\d+)', theme_url)
                        theme_code = theme_code_match.group(1) if theme_code_match else ""
                        change_rate = parse_percentage(cols[3].text)

                        # ìƒìŠ¹ í…Œë§ˆë§Œ ìˆ˜ì§‘
                        if theme_name and theme_code and change_rate > 0:
                            themes.append({
                                'name': theme_name,
                                'code': theme_code,
                                'change_rate': change_rate,
                                'url': f"https://finance.naver.com{theme_url}"
                            })

                    except Exception as e:
                        logging.warning(f"í…Œë§ˆ íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue

                if themes:
                    logging.info(f"âœ… í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ: {len(themes)}ê°œ")
                    return sorted(themes, key=lambda x: x['change_rate'], reverse=True)

            except Exception as e:
                logging.error(f"í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
                if attempt < self.max_retry - 1:
                    time.sleep(1)
                    continue

        logging.error("âŒ í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ì™„ì „ ì‹¤íŒ¨")
        return []

    def _get_theme_stocks(self, theme_code: str, theme_name: str, limit: int = 5) -> List[Dict]:
        """
        íŠ¹ì • í…Œë§ˆì˜ ìƒìœ„ ì¢…ëª© í¬ë¡¤ë§

        Args:
            theme_code: í…Œë§ˆ ì½”ë“œ
            theme_name: í…Œë§ˆëª…
            limit: ìˆ˜ì§‘í•  ì¢…ëª© ìˆ˜

        Returns:
            ì¢…ëª© ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        url = f"https://finance.naver.com/sise/sise_group_detail.naver?type=theme&no={theme_code}"

        for attempt in range(self.max_retry):
            try:
                response = safe_request(url, timeout=10)
                if not response:
                    continue

                response.encoding = 'euc-kr'
                soup = BeautifulSoup(response.text, 'html.parser')

                # ì¢…ëª© í…Œì´ë¸” ì°¾ê¸°
                table = soup.find('table', {'class': 'type_1'})
                if not table:
                    logging.warning(f"  {theme_name}: ì¢…ëª© í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    continue

                stocks = []
                rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸

                for i, row in enumerate(rows):
                    if i >= limit:  # ìƒìœ„ Nê°œë§Œ
                        break

                    try:
                        cols = row.find_all('td')
                        if len(cols) < 6:
                            continue

                        # ì¢…ëª©ëª… ë° ì½”ë“œ
                        stock_link = cols[0].find('a')
                        if not stock_link:
                            continue

                        stock_name = clean_text(stock_link.text)
                        stock_href = stock_link.get('href', '')
                        stock_code_match = re.search(r'code=(\d{6})', stock_href)
                        stock_code = stock_code_match.group(1) if stock_code_match else ""

                        if not stock_code:
                            continue

                        # ê°€ê²© ì •ë³´
                        price = parse_number(cols[1].text) or 0
                        change_rate = parse_percentage(cols[3].text)
                        volume = parse_number(cols[5].text) or 0

                        # í…Œë§ˆ ë‚´ ì „ì²´ ì¢…ëª© ì •ë³´ë„ ìˆ˜ì§‘
                        theme_stocks_info = self._get_all_theme_stocks(soup, theme_name)

                        stock_data = {
                            'stock_code': stock_code,
                            'stock_name': stock_name,
                            'price': price,
                            'change_rate': change_rate,
                            'volume': volume,
                            'themes': [theme_name],  # ì£¼ í…Œë§ˆ
                            'news': [],  # ë‰´ìŠ¤ëŠ” ë‚˜ì¤‘ì— ìˆ˜ì§‘
                            'theme_stocks': {theme_name: theme_stocks_info}
                        }

                        stocks.append(stock_data)

                    except Exception as e:
                        logging.warning(f"  {theme_name} ì¢…ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue

                if stocks:
                    return stocks

            except Exception as e:
                logging.error(f"  {theme_name} í¬ë¡¤ë§ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
                if attempt < self.max_retry - 1:
                    time.sleep(1)
                    continue

        logging.error(f"  âŒ {theme_name} í¬ë¡¤ë§ ì™„ì „ ì‹¤íŒ¨")
        return []

    def _get_all_theme_stocks(self, soup: BeautifulSoup, theme_name: str) -> List[Dict]:
        """
        í…Œë§ˆ ë‚´ ì „ì²´ ì¢…ëª© ì •ë³´ ìˆ˜ì§‘

        Args:
            soup: BeautifulSoup ê°ì²´
            theme_name: í…Œë§ˆëª…

        Returns:
            ì „ì²´ ì¢…ëª© ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            table = soup.find('table', {'class': 'type_1'})
            if not table:
                return []

            all_stocks = []
            rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸

            for row in rows:
                try:
                    cols = row.find_all('td')
                    if len(cols) < 6:
                        continue

                    stock_link = cols[0].find('a')
                    if not stock_link:
                        continue

                    stock_name = clean_text(stock_link.text)
                    stock_href = stock_link.get('href', '')
                    stock_code_match = re.search(r'code=(\d{6})', stock_href)
                    stock_code = stock_code_match.group(1) if stock_code_match else ""

                    if stock_code:
                        price = parse_number(cols[1].text) or 0
                        change_rate = parse_percentage(cols[3].text)

                        all_stocks.append({
                            'stock_code': stock_code,
                            'stock_name': stock_name,
                            'price': price,
                            'change_rate': change_rate
                        })

                except Exception:
                    continue

            return all_stocks

        except Exception as e:
            logging.warning(f"  {theme_name} ì „ì²´ ì¢…ëª© ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    def _collect_stock_news(self, stock_data: List[Dict]) -> None:
        """
        ì¢…ëª©ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘

        Args:
            stock_data: ì¢…ëª© ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ë‰´ìŠ¤ê°€ ì¶”ê°€ë¨)
        """
        for i, stock in enumerate(stock_data):
            try:
                # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                if i % 5 == 0:  # 5ê°œë§ˆë‹¤ ì—…ë°ì´íŠ¸
                    progress = 85 + (10 * i / len(stock_data))
                    message = f"{stock['stock_name']} ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... ({i + 1}/{len(stock_data)})"
                    self._update_progress(progress, message)

                news = self._get_stock_news(stock['stock_code'])
                stock['news'] = news[:5]  # ìµœëŒ€ 5ê°œ ë‰´ìŠ¤

                # ìš”ì²­ ê°„ ì§€ì—°
                time.sleep(0.3)

            except Exception as e:
                logging.warning(f"  {stock['stock_name']} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                stock['news'] = []
                continue

    def _get_stock_news(self, stock_code: str) -> List[Dict]:
        """
        ê°œë³„ ì¢…ëª©ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘

        Args:
            stock_code: ì¢…ëª© ì½”ë“œ

        Returns:
            ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        url = f"https://finance.naver.com/item/news_news.naver?code={stock_code}&page=1"

        try:
            response = safe_request(url, timeout=5)
            if not response:
                return []

            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')

            news_list = []
            news_table = soup.find('table', {'class': 'type5'})

            if news_table:
                news_rows = news_table.find_all('tr')

                for row in news_rows:
                    try:
                        title_cell = row.find('td', {'class': 'title'})
                        if not title_cell:
                            continue

                        title_link = title_cell.find('a')
                        if not title_link:
                            continue

                        title = clean_text(title_link.text)
                        if not title:
                            continue

                        # ë‚ ì§œ ì •ë³´
                        date_cell = row.find('td', {'class': 'date'})
                        date_text = clean_text(date_cell.text) if date_cell else ""

                        # ë‰´ìŠ¤ URL
                        news_url = title_link.get('href', '')
                        if news_url and not news_url.startswith('http'):
                            news_url = urljoin('https://finance.naver.com', news_url)

                        news_list.append({
                            'title': title,
                            'date': date_text,
                            'url': news_url
                        })

                        if len(news_list) >= 5:  # ìµœëŒ€ 5ê°œ
                            break

                    except Exception:
                        continue

            return news_list

        except Exception as e:
            logging.warning(f"ì¢…ëª© {stock_code} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    def _update_progress(self, percent: float, message: str) -> None:
        """
        ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸

        Args:
            percent: ì§„í–‰ í¼ì„¼íŠ¸ (0-100)
            message: ì§„í–‰ ë©”ì‹œì§€
        """
        if self.progress_callback:
            self.progress_callback(percent, message)

        logging.info(f"ğŸ”„ [{percent:.1f}%] {message}")

    def _print_crawling_summary(self, stock_data: List[Dict], target_date: str) -> None:
        """
        í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ ì¶œë ¥

        Args:
            stock_data: ìˆ˜ì§‘ëœ ì¢…ëª© ë°ì´í„°
            target_date: ìˆ˜ì§‘ ë‚ ì§œ
        """
        if not stock_data:
            return

        # í…Œë§ˆë³„ í†µê³„
        theme_stats = {}
        total_news = 0

        for stock in stock_data:
            themes = stock.get('themes', [])
            news_count = len(stock.get('news', []))
            total_news += news_count

            for theme in themes:
                if theme not in theme_stats:
                    theme_stats[theme] = {'stocks': 0, 'news': 0}
                theme_stats[theme]['stocks'] += 1
                theme_stats[theme]['news'] += news_count

        logging.info(f"""
ğŸ¯ í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ ({target_date})
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š ì´ ì¢…ëª©: {len(stock_data)}ê°œ
ğŸ“° ì´ ë‰´ìŠ¤: {total_news}ê°œ
ğŸ·ï¸ í…Œë§ˆ ìˆ˜: {len(theme_stats)}ê°œ
âš¡ í‰ê·  ë‰´ìŠ¤/ì¢…ëª©: {total_news / len(stock_data):.1f}ê°œ

ğŸ“‹ í…Œë§ˆë³„ ìƒì„¸:""")

        for theme, stats in sorted(theme_stats.items(), key=lambda x: x[1]['stocks'], reverse=True):
            logging.info(f"   {theme}: {stats['stocks']}ê°œ ì¢…ëª©, {stats['news']}ê°œ ë‰´ìŠ¤")

        logging.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")


# ì§„í–‰ìƒí™© ì¶”ì ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ (ì›¹ ì¸í„°í˜ì´ìŠ¤ìš©)
crawling_progress = {
    'is_running': False,
    'percent': 0,
    'message': '',
    'start_time': None,
    'end_time': None,
    'success': None,
    'error_message': ''
}