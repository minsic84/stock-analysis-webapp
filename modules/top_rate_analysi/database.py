#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ë“±ë½ìœ¨ìƒìœ„ë¶„ì„ ì „ìš© ë°ì´í„°ë² ì´ìŠ¤ í´ë˜ìŠ¤
- ì™„ì „ ë…ë¦½ì ì¸ DB ì—°ê²° ë° ê´€ë¦¬
- ë‚ ì§œë³„ í…Œì´ë¸” ìë™ ìƒì„±/ê´€ë¦¬
- í¬ë¡¤ë§ ë°ì´í„° ì €ì¥ ë° ì¡°íšŒ
"""

import pymysql
import json
import logging
from datetime import datetime
from typing import List, Dict, Optional, Tuple
import os
from .utils import get_trading_date, get_table_name


class TopRateDatabase:
    """ë“±ë½ìœ¨ìƒìœ„ë¶„ì„ ì „ìš© ë°ì´í„°ë² ì´ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì • ì´ˆê¸°í™”"""
        self.db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': int(os.getenv('DB_PORT', 3306)),
            'user': os.getenv('DB_USER', 'stock_user'),
            'password': os.getenv('DB_PASSWORD', 'StockPass2025!'),
            'charset': 'utf8mb4',
            'autocommit': True
        }

        # ì „ìš© í¬ë¡¤ë§ ë°ì´í„°ë² ì´ìŠ¤
        self.crawling_db = 'crawling_db'

        # ì—°ê²° í…ŒìŠ¤íŠ¸
        self._test_connection()

    def _test_connection(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            connection = self.get_connection()
            connection.close()
            logging.info("âœ… TopRateDatabase ì—°ê²° ì„±ê³µ")
            return True
        except Exception as e:
            logging.error(f"âŒ TopRateDatabase ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def get_connection(self, database: str = None) -> pymysql.Connection:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë°˜í™˜

        Args:
            database: ì—°ê²°í•  ë°ì´í„°ë² ì´ìŠ¤ëª… (Noneì´ë©´ ê¸°ë³¸ ì—°ê²°)

        Returns:
            pymysql.Connection ê°ì²´
        """
        config = self.db_config.copy()
        if database:
            config['database'] = database
        return pymysql.connect(**config)

    def setup_crawling_database(self) -> bool:
        """
        í¬ë¡¤ë§ ì „ìš© ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            connection = self.get_connection()
            cursor = connection.cursor()

            # ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´)
            cursor.execute(
                f"CREATE DATABASE IF NOT EXISTS {self.crawling_db} "
                "CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci"
            )

            cursor.close()
            connection.close()

            logging.info(f"âœ… í¬ë¡¤ë§ ë°ì´í„°ë² ì´ìŠ¤ ({self.crawling_db}) ì„¤ì • ì™„ë£Œ")
            return True

        except Exception as e:
            logging.error(f"âŒ í¬ë¡¤ë§ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False

    def setup_theme_table(self, date_str: str) -> str:
        """
        ë‚ ì§œë³„ í…Œë§ˆ í…Œì´ë¸” ìƒì„± (ê¸°ì¡´ í…Œì´ë¸” ë®ì–´ì“°ê¸°)

        Args:
            date_str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ

        Returns:
            ìƒì„±ëœ í…Œì´ë¸”ëª…
        """
        table_name = get_table_name(date_str)

        try:
            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ (ë®ì–´ì“°ê¸°)
            cursor.execute(f"DROP TABLE IF EXISTS {table_name}")

            # ìƒˆ í…Œì´ë¸” ìƒì„±
            create_sql = f"""
            CREATE TABLE {table_name} (
                id INT AUTO_INCREMENT PRIMARY KEY,
                stock_code VARCHAR(10) NOT NULL,
                stock_name VARCHAR(100) NOT NULL,
                price INT DEFAULT 0,
                change_rate DECIMAL(5,2) DEFAULT 0.00,
                volume BIGINT DEFAULT 0,
                themes JSON,
                news JSON,
                theme_stocks JSON,
                crawled_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_stock_code (stock_code),
                INDEX idx_change_rate (change_rate),
                INDEX idx_crawled_at (crawled_at)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """

            cursor.execute(create_sql)
            cursor.close()
            connection.close()

            logging.info(f"âœ… í…Œë§ˆ í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {table_name}")
            return table_name

        except Exception as e:
            logging.error(f"âŒ í…Œë§ˆ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def save_theme_data(self, table_name: str, theme_data: List[Dict]) -> bool:
        """
        í…Œë§ˆ í¬ë¡¤ë§ ë°ì´í„° ì €ì¥

        Args:
            table_name: ì €ì¥í•  í…Œì´ë¸”ëª…
            theme_data: ì €ì¥í•  í…Œë§ˆ ë°ì´í„° ë¦¬ìŠ¤íŠ¸

        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        if not theme_data:
            logging.warning("ì €ì¥í•  í…Œë§ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False

        try:
            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            insert_sql = f"""
            INSERT INTO {table_name} 
            (stock_code, stock_name, price, change_rate, volume, themes, news, theme_stocks)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """

            success_count = 0

            for data in theme_data:
                try:
                    cursor.execute(insert_sql, (
                        data.get('stock_code', ''),
                        data.get('stock_name', ''),
                        data.get('price', 0),
                        data.get('change_rate', 0.0),
                        data.get('volume', 0),
                        json.dumps(data.get('themes', []), ensure_ascii=False),
                        json.dumps(data.get('news', []), ensure_ascii=False),
                        json.dumps(data.get('theme_stocks', {}), ensure_ascii=False)
                    ))
                    success_count += 1

                except Exception as e:
                    logging.error(f"ê°œë³„ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ ({data.get('stock_name', 'Unknown')}): {e}")
                    continue

            cursor.close()
            connection.close()

            logging.info(f"âœ… í…Œë§ˆ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {success_count}/{len(theme_data)}ê°œ")
            return success_count > 0

        except Exception as e:
            logging.error(f"âŒ í…Œë§ˆ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def get_theme_data(self, date_str: str) -> List[Dict]:
        """
        ë‚ ì§œë³„ í…Œë§ˆ ë°ì´í„° ì¡°íšŒ

        Args:
            date_str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ

        Returns:
            í…Œë§ˆ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        table_name = get_table_name(date_str)

        try:
            if not self.check_table_exists(table_name):
                logging.warning(f"í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {table_name}")
                return []

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor(pymysql.cursors.DictCursor)

            query = f"""
            SELECT stock_code, stock_name, price, change_rate, volume, 
                   themes, news, theme_stocks, crawled_at
            FROM {table_name} 
            ORDER BY change_rate DESC
            """

            cursor.execute(query)
            results = cursor.fetchall()

            # JSON í•„ë“œ íŒŒì‹±
            for result in results:
                for json_field in ['themes', 'news', 'theme_stocks']:
                    if result[json_field]:
                        try:
                            result[json_field] = json.loads(result[json_field])
                        except json.JSONDecodeError:
                            result[json_field] = []

            cursor.close()
            connection.close()

            logging.info(f"âœ… í…Œë§ˆ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {len(results)}ê°œ ({table_name})")
            return results

        except Exception as e:
            logging.error(f"âŒ í…Œë§ˆ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def get_theme_summary(self, date_str: str) -> List[Dict]:
        """
        í…Œë§ˆë³„ ìš”ì•½ í†µê³„ ì¡°íšŒ

        Args:
            date_str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ

        Returns:
            í…Œë§ˆë³„ ìš”ì•½ ë°ì´í„°
        """
        table_name = get_table_name(date_str)

        try:
            if not self.check_table_exists(table_name):
                return []

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor(pymysql.cursors.DictCursor)

            # í…Œë§ˆë³„ ì§‘ê³„ ì¿¼ë¦¬
            query = f"""
            SELECT 
                JSON_UNQUOTE(JSON_EXTRACT(themes, '$[0]')) as theme_name,
                COUNT(*) as stock_count,
                AVG(change_rate) as avg_change_rate,
                MAX(change_rate) as max_change_rate,
                SUM(CASE WHEN change_rate > 0 THEN 1 ELSE 0 END) as rising_stocks,
                (
                    SELECT COUNT(*)
                    FROM {table_name} t2 
                    WHERE JSON_EXTRACT(t2.news, '$') != 'null' 
                    AND JSON_LENGTH(t2.news) > 0
                    AND JSON_EXTRACT(t2.themes, '$[0]') = JSON_EXTRACT(themes, '$[0]')
                ) as total_news,
                (
                    SELECT CONCAT(stock_name, ' (+', ROUND(change_rate, 1), '%)')
                    FROM {table_name} t3
                    WHERE JSON_EXTRACT(t3.themes, '$[0]') = JSON_EXTRACT(themes, '$[0]')
                    ORDER BY change_rate DESC 
                    LIMIT 1
                ) as top_stock
            FROM {table_name}
            WHERE JSON_LENGTH(themes) > 0
            GROUP BY JSON_UNQUOTE(JSON_EXTRACT(themes, '$[0]'))
            HAVING theme_name IS NOT NULL AND theme_name != ''
            ORDER BY avg_change_rate DESC
            """

            cursor.execute(query)
            results = cursor.fetchall()

            cursor.close()
            connection.close()

            logging.info(f"âœ… í…Œë§ˆ ìš”ì•½ ì¡°íšŒ ì™„ë£Œ: {len(results)}ê°œ í…Œë§ˆ")
            return results

        except Exception as e:
            logging.error(f"âŒ í…Œë§ˆ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def get_theme_detail(self, date_str: str, theme_name: str) -> Dict:
        """
        íŠ¹ì • í…Œë§ˆì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ

        Args:
            date_str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ
            theme_name: í…Œë§ˆëª…

        Returns:
            í…Œë§ˆ ìƒì„¸ ì •ë³´
        """
        table_name = get_table_name(date_str)

        try:
            if not self.check_table_exists(table_name):
                return {}

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor(pymysql.cursors.DictCursor)

            # í•´ë‹¹ í…Œë§ˆ ì¢…ëª©ë“¤ ì¡°íšŒ
            query = f"""
            SELECT stock_code, stock_name, price, change_rate, volume, news
            FROM {table_name}
            WHERE JSON_CONTAINS(themes, JSON_QUOTE(%s))
            ORDER BY change_rate DESC
            """

            cursor.execute(query, (theme_name,))
            stocks = cursor.fetchall()

            # JSON í•„ë“œ íŒŒì‹±
            all_news = []
            for stock in stocks:
                if stock['news']:
                    try:
                        stock_news = json.loads(stock['news'])
                        all_news.extend(stock_news)
                        stock['news'] = stock_news
                    except json.JSONDecodeError:
                        stock['news'] = []

            cursor.close()
            connection.close()

            if not stocks:
                return {}

            # í…Œë§ˆ í†µê³„ ê³„ì‚°
            change_rates = [stock['change_rate'] for stock in stocks]
            rising_count = len([rate for rate in change_rates if rate > 0])

            result = {
                'theme_name': theme_name,
                'stock_count': len(stocks),
                'avg_change_rate': sum(change_rates) / len(change_rates),
                'max_change_rate': max(change_rates),
                'rising_stocks': rising_count,
                'total_news': len(all_news),
                'stocks': stocks,
                'news': all_news[:10]  # ìƒìœ„ 10ê°œ ë‰´ìŠ¤ë§Œ
            }

            logging.info(f"âœ… í…Œë§ˆ ìƒì„¸ì •ë³´ ì¡°íšŒ ì™„ë£Œ: {theme_name} ({len(stocks)}ê°œ ì¢…ëª©)")
            return result

        except Exception as e:
            logging.error(f"âŒ í…Œë§ˆ ìƒì„¸ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def check_table_exists(self, table_name: str) -> bool:
        """
        í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸

        Args:
            table_name: í™•ì¸í•  í…Œì´ë¸”ëª…

        Returns:
            ì¡´ì¬ ì—¬ë¶€
        """
        try:
            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            cursor.execute(f"SHOW TABLES LIKE '{table_name}'")
            exists = cursor.fetchone() is not None

            cursor.close()
            connection.close()

            return exists

        except Exception as e:
            logging.error(f"í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

    def get_available_dates(self) -> List[str]:
        """
        ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ìˆëŠ” ë‚ ì§œ ëª©ë¡ ì¡°íšŒ

        Returns:
            ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ (YYYY-MM-DD í˜•ì‹)
        """
        try:
            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            cursor.execute("SHOW TABLES LIKE 'theme_%'")
            tables = cursor.fetchall()

            cursor.close()
            connection.close()

            # í…Œì´ë¸”ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
            dates = []
            for (table_name,) in tables:
                if table_name.startswith('theme_') and len(table_name) == 14:  # theme_YYYYMMDD
                    date_part = table_name[6:]  # YYYYMMDD
                    try:
                        # YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        formatted_date = f"{date_part[:4]}-{date_part[4:6]}-{date_part[6:8]}"
                        dates.append(formatted_date)
                    except:
                        continue

            dates.sort(reverse=True)  # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬
            return dates

        except Exception as e:
            logging.error(f"ë‚ ì§œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def delete_old_data(self, keep_days: int = 30) -> bool:
        """
        ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ (ë³´ê´€ ê¸°ê°„ ì´ˆê³¼)

        Args:
            keep_days: ë³´ê´€í•  ì¼ìˆ˜

        Returns:
            ì‚­ì œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            from datetime import timedelta

            cutoff_date = datetime.now() - timedelta(days=keep_days)
            cutoff_str = cutoff_date.strftime('%Y%m%d')

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor()

            # ì‚­ì œ ëŒ€ìƒ í…Œì´ë¸” ì¡°íšŒ
            cursor.execute("SHOW TABLES LIKE 'theme_%'")
            tables = cursor.fetchall()

            deleted_count = 0
            for (table_name,) in tables:
                if table_name.startswith('theme_') and len(table_name) == 14:
                    date_part = table_name[6:]  # YYYYMMDD
                    if date_part < cutoff_str:
                        cursor.execute(f"DROP TABLE {table_name}")
                        deleted_count += 1
                        logging.info(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ í…Œì´ë¸” ì‚­ì œ: {table_name}")

            cursor.close()
            connection.close()

            if deleted_count > 0:
                logging.info(f"âœ… ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {deleted_count}ê°œ í…Œì´ë¸” ì‚­ì œ")
            else:
                logging.info("â„¹ï¸ ì‚­ì œí•  ì˜¤ë˜ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

            return True

        except Exception as e:
            logging.error(f"âŒ ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False

    def get_crawling_status(self, date_str: str) -> Dict:
        """
        í¬ë¡¤ë§ ìƒíƒœ ì •ë³´ ì¡°íšŒ

        Args:
            date_str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ

        Returns:
            í¬ë¡¤ë§ ìƒíƒœ ì •ë³´
        """
        table_name = get_table_name(date_str)

        try:
            if not self.check_table_exists(table_name):
                return {
                    'exists': False,
                    'total_stocks': 0,
                    'last_updated': None,
                    'theme_count': 0
                }

            connection = self.get_connection(self.crawling_db)
            cursor = connection.cursor(pymysql.cursors.DictCursor)

            # ê¸°ë³¸ í†µê³„
            cursor.execute(f"SELECT COUNT(*) as total FROM {table_name}")
            total_result = cursor.fetchone()

            # ìµœê·¼ ì—…ë°ì´íŠ¸ ì‹œê°„
            cursor.execute(f"SELECT MAX(crawled_at) as last_updated FROM {table_name}")
            time_result = cursor.fetchone()

            # í…Œë§ˆ ìˆ˜
            cursor.execute(f"""
                SELECT COUNT(DISTINCT JSON_UNQUOTE(JSON_EXTRACT(themes, '$[0]'))) as theme_count
                FROM {table_name}
                WHERE JSON_LENGTH(themes) > 0
            """)
            theme_result = cursor.fetchone()

            cursor.close()
            connection.close()

            return {
                'exists': True,
                'total_stocks': total_result['total'] if total_result else 0,
                'last_updated': time_result['last_updated'] if time_result else None,
                'theme_count': theme_result['theme_count'] if theme_result else 0
            }

        except Exception as e:
            logging.error(f"âŒ í¬ë¡¤ë§ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'exists': False,
                'total_stocks': 0,
                'last_updated': None,
                'theme_count': 0
            }